name: Daily News Scrape

on:
  schedule:
    # 매일 09:00, 13:00, 17:00 (KST = UTC+9, 즉 UTC 00:00, 04:00, 08:00)
    - cron: '0 0 * * *'   # 09:00 KST
    - cron: '0 4 * * *'   # 13:00 KST
    - cron: '0 8 * * *'   # 17:00 KST
  workflow_dispatch:  # 수동 실행 가능

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    env:
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
      BOT_API_KEY: ${{ secrets.BOT_API_KEY }}
      BOT_API_URL: ${{ secrets.BOT_API_URL }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          python -m playwright install chromium
      
      - name: Run Naju Scraper
        run: python scrapers/naju_scraper.py api
        continue-on-error: true
      
      - name: Run Gwangju Scraper
        run: python scrapers/universal_scraper.py --region gwangju --days 1
        continue-on-error: true
      
      - name: Run Jeonnam Scraper (Playwright)
        run: python scrapers/jeonnam_scraper.py --days 1 api
        continue-on-error: true
      
      - name: Run RSS Collector
        run: python scrapers/rss_collector.py api
        continue-on-error: true
      
      - name: Finish
        run: echo "Daily scrape completed at $(date)"
