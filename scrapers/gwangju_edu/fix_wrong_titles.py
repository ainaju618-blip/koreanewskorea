# -*- coding: utf-8 -*-
"""
ê´‘ì£¼êµìœ¡ì²­ ê¸°ì¡´ ê¸°ì‚¬ ì œëª©+ë³¸ë¬¸ ì—…ë°ì´íŠ¸ ìŠ¤í¬ë¦½íŠ¸ v2
- ì˜ëª»ëœ ì œëª© "ê´‘ì£¼ê´‘ì—­ì‹œêµìœ¡ì²­í™ë³´ê´€"ì„ ì‹¤ì œ ì œëª©ìœ¼ë¡œ ìˆ˜ì •
- ë³¸ë¬¸ë„ ì¬ì¶”ì¶œí•˜ì—¬ ì—…ë°ì´íŠ¸
"""

import os
import sys
import time
import re

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from playwright.sync_api import sync_playwright
from supabase import create_client

# Supabase ì„¤ì •
SUPABASE_URL = os.getenv("SUPABASE_URL", "https://oaciprcdcdegwufydjhv.supabase.co")
SUPABASE_KEY = os.getenv("SUPABASE_KEY", "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Im9hY2lwcmNkY2RlZ3d1Znlkamh2Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzMxNjg3NjgsImV4cCI6MjA0ODc0NDc2OH0.z8EfkVKPBSr1ot4HfBWmHWNBTMBqJCkcKLdKOGguJ_w")

supabase = create_client(SUPABASE_URL, SUPABASE_KEY)


def extract_title(page) -> str:
    """JavaScriptë¡œ ì œëª© ì¶”ì¶œ (view_top ì˜ì—­ì—ì„œ)"""
    try:
        title = page.evaluate("""() => {
            const viewTop = document.querySelector('div.view_top');
            if (!viewTop) return '';
            
            const text = viewTop.textContent || '';
            const lines = text.split('\\n').map(l => l.trim()).filter(l => l.length > 5);
            
            for (const line of lines) {
                if (!line.includes('ì‘ì„±ì¼:') && 
                    !line.includes('ì‘ì„±ì:') && 
                    !line.includes('ê¸°ê´€ëª…') &&
                    !line.includes('ìë£Œë¬¸ì˜') &&
                    !line.includes('ì¡°íšŒìˆ˜') &&
                    !line.includes('ì¶”ì²œìˆ˜') &&
                    !line.includes('ë“±ë¡ì¼')) {
                    return line;
                }
            }
            return lines[0] || '';
        }""")
        return title.strip() if title else ""
    except:
        return ""


def extract_content(page, title: str) -> str:
    """JavaScriptë¡œ ë³¸ë¬¸ ì¶”ì¶œ (ì œëª© ì˜ì—­ ì œì™¸)"""
    content = ""
    
    try:
        content = page.evaluate("""() => {
            const boardPress = document.querySelector('div.board_press');
            if (!boardPress) return '';
            
            const clone = boardPress.cloneNode(true);
            
            const excludeSelectors = [
                'div.view_top',
                'div.inquiry',
                'div.writer',
                'div.file_list',
                'div.view_bottom',
                '.btn_wrap',
            ];
            
            excludeSelectors.forEach(sel => {
                const els = clone.querySelectorAll(sel);
                els.forEach(el => el.remove());
            });
            
            return clone.textContent?.trim() || '';
        }""")
    except Exception as e:
        print(f"      âš ï¸ JS ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
    
    if content:
        noise_patterns = [
            r'HOME\s*',
            r'ë³´ë„/í•´ëª…ìë£Œ\s*',
            r'ì˜¤ëŠ˜ì˜ ë³´ë„/í•´ëª…ìë£Œë€ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤\.?\s*',
            r'ë³´ë„ìë£Œ\s*(?=[^\w]|$)',
            r'ë§Œì¡±ë„\s*ì¡°ì‚¬.*',
            r'ì €ì‘ê¶Œ.*',
            r'COPYRIGHT.*',
            r'ëª©ë¡\s*ì´ì „ê¸€\s*ë‹¤ìŒê¸€.*',
            r'ìë£Œë¬¸ì˜\s*:.*',
        ]
        for pattern in noise_patterns:
            content = re.sub(pattern, '', content, flags=re.IGNORECASE)
        
        if title and content.startswith(title):
            content = content[len(title):].strip()
        
        content = re.sub(r'\n{3,}', '\n\n', content)
        content = re.sub(r' {2,}', ' ', content)
        content = content.strip()[:5000]
    
    return content


def main():
    print("ğŸ”„ ê´‘ì£¼êµìœ¡ì²­ ì˜ëª»ëœ ì œëª© ìˆ˜ì • ì‹œì‘")
    
    # DBì—ì„œ ì˜ëª»ëœ ì œëª©ì„ ê°€ì§„ ê¸°ì‚¬ ì¡°íšŒ
    result = supabase.table('posts').select('id, title, source_url, content').eq('category', 'ê´‘ì£¼êµìœ¡ì²­').execute()
    posts = result.data or []
    
    # ì˜ëª»ëœ ì œëª©ì„ ê°€ì§„ ê¸°ì‚¬ë§Œ í•„í„°ë§
    bad_posts = [p for p in posts if p.get('title', '').strip() in ['ê´‘ì£¼ê´‘ì—­ì‹œêµìœ¡ì²­í™ë³´ê´€', 'ê´‘ì£¼êµìœ¡ì²­', '']]
    
    print(f"   ğŸ“Š ì´ {len(posts)}ê°œ ì¤‘ {len(bad_posts)}ê°œ ê¸°ì‚¬ ì œëª© ìˆ˜ì • í•„ìš”")
    
    if not bad_posts:
        print("   âœ… ìˆ˜ì •ì´ í•„ìš”í•œ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    updated = 0
    
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        page = browser.new_page()
        
        for i, post in enumerate(bad_posts):
            post_id = post['id']
            old_title = post['title']
            source_url = post.get('source_url', '')
            
            if not source_url:
                print(f"   [{i+1}/{len(bad_posts)}] âš ï¸ source_url ì—†ìŒ")
                continue
            
            print(f"   [{i+1}/{len(bad_posts)}] ğŸ”„ ìˆ˜ì • ì¤‘: {source_url[-30:]}...")
            
            try:
                page.goto(source_url, timeout=30000)
                time.sleep(2)
                
                # ì œëª© ì¶”ì¶œ
                new_title = extract_title(page)
                
                if not new_title or len(new_title) < 5:
                    print(f"      âš ï¸ ì œëª© ì¶”ì¶œ ì‹¤íŒ¨")
                    continue
                
                # ë³¸ë¬¸ ì¶”ì¶œ
                new_content = extract_content(page, new_title)
                
                # DB ì—…ë°ì´íŠ¸
                update_data = {'title': new_title}
                if new_content and len(new_content) > 100:
                    update_data['content'] = new_content
                
                supabase.table('posts').update(update_data).eq('id', post_id).execute()
                updated += 1
                print(f"      âœ… ì œëª© ìˆ˜ì •: {new_title[:40]}...")
            
            except Exception as e:
                print(f"      âŒ ì˜¤ë¥˜: {e}")
            
            time.sleep(1)
        
        browser.close()
    
    print(f"\nğŸ‰ ì™„ë£Œ: {updated}/{len(bad_posts)}ê°œ ê¸°ì‚¬ ì œëª© ìˆ˜ì •ë¨")


if __name__ == "__main__":
    main()
