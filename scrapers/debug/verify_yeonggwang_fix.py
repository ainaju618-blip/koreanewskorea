
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from scrapers.yeonggwang.yeonggwang_scraper import collect_articles, fetch_detail, build_list_url, build_detail_url
from playwright.sync_api import sync_playwright
import time

def verify_fix():
    print("ğŸ” ì˜ê´‘êµ°ì²­ ë³¸ë¬¸ ì¶”ì¶œ í…ŒìŠ¤íŠ¸ (ê³µê³µëˆ„ë¦¬ ì œì™¸ í™•ì¸)")
    
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        page = browser.new_page()
        
        # 1. Get List
        list_url = build_list_url(0)
        page.goto(list_url)
        time.sleep(2)
        
        # Get first 6 links
        links = page.locator('table tbody tr a[href*="bs_idx"]').all()
        targets = []
        for link in links:
            href = link.get_attribute('href')
            if href:
                targets.append(href)
            if len(targets) >= 6:
                break
                
        print(f"ğŸ“„ ìˆ˜ì§‘ ëŒ€ìƒ: {len(targets)}ê°œ")
        
        for i, href in enumerate(targets):
            full_url = "https://www.yeonggwang.go.kr/bbs/" + href if not href.startswith("http") else href
            print(f"\n[{i+1}/6] URL: {full_url}")
            
            content, thumb, date = fetch_detail(page, full_url)
            
            print(f"   ğŸ“… ë‚ ì§œ: {date}")
            print(f"   ğŸ–¼ï¸ ì´ë¯¸ì§€: {'ìˆìŒ' if thumb else 'ì—†ìŒ'}")
            print(f"   ğŸ“ ë³¸ë¬¸ ê¸¸ì´: {len(content)}")
            print(f"   ğŸ“ ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸° (100ì):\n   {content[:100].replace('\n', ' ')}...")
            
            if "ê³µê³µëˆ„ë¦¬" in content:
                print("   âŒ ì‹¤íŒ¨: ë³¸ë¬¸ì— 'ê³µê³µëˆ„ë¦¬' í…ìŠ¤íŠ¸ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤!")
            else:
                print("   âœ… í†µê³¼: 'ê³µê³µëˆ„ë¦¬' í…ìŠ¤íŠ¸ ì—†ìŒ")
                
        browser.close()

if __name__ == "__main__":
    verify_fix()
