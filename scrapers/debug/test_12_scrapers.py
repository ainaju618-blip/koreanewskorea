"""12ê°œ ì„±ê³µ ìŠ¤í¬ë˜í¼ë§Œ 1ê°œì”© ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
import sys
import os
from urllib.parse import urljoin

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from playwright.sync_api import sync_playwright

# ì„±ê³µí•œ 12ê°œ ìŠ¤í¬ë˜í¼ë§Œ
SCRAPERS = [
    {'code': 'jeonnam', 'name': 'ì „ë‚¨ë„', 'file': 'jeonnam_scraper'},
    {'code': 'mokpo', 'name': 'ëª©í¬ì‹œ', 'file': 'mokpo_scraper'},
    {'code': 'yeosu', 'name': 'ì—¬ìˆ˜ì‹œ', 'file': 'yeosu_scraper'},
    {'code': 'suncheon', 'name': 'ìˆœì²œì‹œ', 'file': 'suncheon_scraper'},
    {'code': 'naju', 'name': 'ë‚˜ì£¼ì‹œ', 'file': 'naju_scraper'},
    {'code': 'gwangyang', 'name': 'ê´‘ì–‘ì‹œ', 'file': 'gwangyang_scraper'},
    {'code': 'gokseong', 'name': 'ê³¡ì„±êµ°', 'file': 'gokseong_scraper'},
    {'code': 'gurye', 'name': 'êµ¬ë¡€êµ°', 'file': 'gurye_scraper'},
    {'code': 'hwasun', 'name': 'í™”ìˆœêµ°', 'file': 'hwasun_scraper'},
    {'code': 'hampyeong', 'name': 'í•¨í‰êµ°', 'file': 'hampyeong_scraper'},
    {'code': 'yeonggwang', 'name': 'ì˜ê´‘êµ°', 'file': 'yeonggwang_scraper'},
    {'code': 'wando', 'name': 'ì™„ë„êµ°', 'file': 'wando_scraper'},
]

def extract_one(module, context):
    """1ê°œ ê¸°ì‚¬ ì¶”ì¶œ"""
    from utils.scraper_utils import safe_goto, wait_and_find, safe_get_text, safe_get_attr
    
    result = {'title': '', 'content': '', 'image': '', 'status': 'âŒ'}
    
    try:
        list_url = getattr(module, 'LIST_URL', '')
        base_url = getattr(module, 'BASE_URL', '')
        list_sels = getattr(module, 'LIST_SELECTORS', [])
        content_sels = getattr(module, 'CONTENT_SELECTORS', [])
        
        page = context.new_page()
        page.goto(list_url, timeout=20000, wait_until='domcontentloaded')
        page.wait_for_timeout(2000)
        
        # ë¦¬ìŠ¤íŠ¸ì—ì„œ ì²« ê¸°ì‚¬
        link = None
        for sel in list_sels:
            items = page.locator(sel)
            if items.count() > 0:
                link = items.first
                break
        
        if not link:
            page.close()
            return result
        
        result['title'] = link.inner_text().strip()[:40]
        href = link.get_attribute('href')
        
        # ìƒì„¸ í˜ì´ì§€
        try:
            with page.expect_navigation(timeout=10000):
                link.click()
            page.wait_for_timeout(2000)
        except:
            if href:
                page.goto(urljoin(base_url, href), timeout=15000)
                page.wait_for_timeout(2000)
        
        # ë³¸ë¬¸
        for sel in content_sels:
            elem = page.locator(sel)
            if elem.count() > 0:
                text = elem.first.inner_text()[:100].replace('\n', ' ')
                if text:
                    result['content'] = text[:50] + '...'
                    break
        
        # ì´ë¯¸ì§€ - í–¥ìƒëœ ì¶”ì¶œ ì‚¬ìš©
        from utils.image_extractor import extract_thumbnail
        img = extract_thumbnail(page, base_url, content_sels)
        if img:
            result['image'] = img[:60] + '...' if len(img) > 60 else img
        
        result['status'] = 'âœ…'
        page.close()
        
    except Exception as e:
        result['status'] = f'âŒ {str(e)[:20]}'
    
    return result


def main():
    print("=" * 100)
    print("ğŸ” 12ê°œ ì„±ê³µ ìŠ¤í¬ë˜í¼ ê²€ì¦")
    print("=" * 100)
    
    results = []
    
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        context = browser.new_context(user_agent='Mozilla/5.0')
        
        for s in SCRAPERS:
            print(f"\nğŸ“ {s['name']}...")
            try:
                module = __import__(s['file'])
                r = extract_one(module, context)
                r['name'] = s['name']
                results.append(r)
                
                print(f"   ìƒíƒœ: {r['status']}")
                print(f"   ì œëª©: {r['title']}")
                print(f"   ë³¸ë¬¸: {r['content']}")
                print(f"   ì´ë¯¸ì§€: {r['image'] or 'ì—†ìŒ'}")
            except Exception as e:
                print(f"   âŒ ì˜¤ë¥˜: {e}")
                results.append({'name': s['name'], 'status': 'âŒ', 'image': ''})
        
        browser.close()
    
    # ìš”ì•½
    print("\n" + "=" * 100)
    print("ğŸ“Š ìµœì¢… ìš”ì•½")
    print("=" * 100)
    
    print(f"\n{'ì§€ì—­':<12} | {'ìƒíƒœ':^6} | {'ì œëª©':<35} | {'ì´ë¯¸ì§€':^10}")
    print("-" * 100)
    
    img_count = 0
    for r in results:
        has_img = 'âœ…' if r.get('image') else 'âŒ'
        if r.get('image'):
            img_count += 1
        title = r.get('title', '')[:30] + '...' if len(r.get('title', '')) > 30 else r.get('title', '')
        print(f"{r['name']:<12} | {r['status']:^6} | {title:<35} | {has_img:^10}")
    
    print("-" * 100)
    print(f"\nâœ… ì´ {len([r for r in results if r['status'] == 'âœ…'])}/12ê°œ ì„±ê³µ")
    print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ì¶”ì¶œ: {img_count}/12ê°œ")


if __name__ == "__main__":
    main()
