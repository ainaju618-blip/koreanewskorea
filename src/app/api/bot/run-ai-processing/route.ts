import { NextRequest, NextResponse } from 'next/server';
import { createClient } from '@supabase/supabase-js';
import { spawn } from 'child_process';
import os from 'os';

const isWindows = os.platform() === 'win32';

// Global state for processing control (toggle)
let isProcessingActive = false;
let shouldStopProcessing = false;
let processingStats = {
    total: 0,
    processed: 0,
    published: 0,
    held: 0,
    failed: 0,
    startedAt: null as string | null
};

const supabaseAdmin = createClient(
    process.env.NEXT_PUBLIC_SUPABASE_URL!,
    process.env.SUPABASE_SERVICE_ROLE_KEY!
);

// Local Ollama configuration - Linkbricks Korean 8B (Grade A verified, 105s)
const OLLAMA_BASE_URL = process.env.OLLAMA_BASE_URL || 'http://localhost:11434';
const PRIMARY_MODEL = 'benedict/linkbricks-llama3.1-korean:8b';  // Grade A verified, Korean-focused
const FALLBACK_MODEL = 'solar:10.7b';     // Fallback (bilingual but reliable)

// Ollama API settings - Korean model optimized parameters
const NUM_CTX = 4096;             // Reduced from 8192 (Korean KV cache optimization)
const NUM_PREDICT = 2048;         // Reduced from 4096
const API_TIMEOUT_MS = 180000;    // 3 minutes (Korean models faster with optimized settings)

// Start Ollama directly (no API endpoint dependency - fixes port mismatch issue)
async function ensureOllamaRunning(maxRetries: number = 3): Promise<{ success: boolean; message: string }> {
    console.log('[Ollama] Ensuring Ollama is running...');

    // First check if already running
    try {
        const healthCheck = await fetch(`${OLLAMA_BASE_URL}/api/tags`, {
            signal: AbortSignal.timeout(3000)
        });
        if (healthCheck.ok) {
            console.log('[Ollama] Already running and healthy');
            return { success: true, message: 'Ollama already running' };
        }
    } catch {
        console.log('[Ollama] Not running, attempting to start directly...');
    }

    // Try to start Ollama directly (not via API - fixes port mismatch when dev server uses different port)
    for (let attempt = 1; attempt <= maxRetries; attempt++) {
        try {
            console.log(`[Ollama] Direct start attempt ${attempt}/${maxRetries}...`);

            // Spawn Ollama serve directly
            if (isWindows) {
                const ollamaProcess = spawn('powershell', [
                    '-WindowStyle', 'Hidden',
                    '-Command', 'Start-Process -FilePath ollama -ArgumentList serve -WindowStyle Hidden'
                ], {
                    detached: true,
                    stdio: 'ignore',
                    windowsHide: true
                });
                ollamaProcess.unref();
            } else {
                const ollamaProcess = spawn('ollama', ['serve'], {
                    shell: true,
                    detached: true,
                    stdio: 'ignore'
                });
                ollamaProcess.unref();
            }

            // Wait for Ollama to be ready (poll health endpoint)
            const maxWaitTime = 15000; // 15 seconds
            const startTime = Date.now();
            let lastError = '';

            while (Date.now() - startTime < maxWaitTime) {
                try {
                    const healthCheck = await fetch(`${OLLAMA_BASE_URL}/api/tags`, {
                        signal: AbortSignal.timeout(2000)
                    });
                    if (healthCheck.ok) {
                        console.log('[Ollama] Started successfully (direct spawn)');
                        return { success: true, message: 'Ollama started' };
                    }
                    lastError = `HTTP ${healthCheck.status}`;
                } catch (e) {
                    lastError = e instanceof Error ? e.message : 'Connection refused';
                }
                await new Promise(resolve => setTimeout(resolve, 1000));
            }

            console.log(`[Ollama] Start attempt ${attempt} timeout after ${maxWaitTime/1000}s: ${lastError}`);

        } catch (error) {
            const message = error instanceof Error ? error.message : 'Unknown error';
            console.log(`[Ollama] Start attempt ${attempt} error: ${message}`);
        }

        // Wait before retry (increasing delay)
        if (attempt < maxRetries) {
            const delay = attempt * 2000; // 2s, 4s
            console.log(`[Ollama] Waiting ${delay / 1000}s before retry...`);
            await new Promise(resolve => setTimeout(resolve, delay));
        }
    }

    return { success: false, message: `Failed to start Ollama after ${maxRetries} attempts` };
}

// Call local Ollama API with timeout and expert-recommended parameters
async function callOllama(prompt: string, model: string = PRIMARY_MODEL): Promise<string> {
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), API_TIMEOUT_MS);

    try {
        console.log(`[Ollama] Calling ${model}...`);
        const startTime = Date.now();

        const response = await fetch(`${OLLAMA_BASE_URL}/api/generate`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                model: model,
                prompt: prompt,
                stream: false,
                options: {
                    num_ctx: NUM_CTX,
                    num_predict: NUM_PREDICT,
                    temperature: 0.35,      // Expert: balanced output
                    top_p: 0.9,
                    repeat_penalty: 1.02,   // Expert: lowered to preserve length
                    num_gpu: 32,            // GPU layers limit for Korean models
                    gpu_layers: 32          // Prevent VRAM overflow on RTX 4070 12GB
                }
            }),
            signal: controller.signal
        });

        clearTimeout(timeoutId);
        const elapsed = ((Date.now() - startTime) / 1000).toFixed(1);

        if (!response.ok) {
            throw new Error(`Ollama API error: ${response.status}`);
        }

        const data = await response.json();
        console.log(`[Ollama] Response in ${elapsed}s, output: ${(data.response || '').length} chars`);
        return data.response || '';
    } catch (error: unknown) {
        clearTimeout(timeoutId);
        if (error instanceof Error && error.name === 'AbortError') {
            throw new Error(`Ollama API timeout after ${API_TIMEOUT_MS / 1000}s`);
        }
        throw error;
    }
}

// Validate output: check for English ratio and length
function validateOutput(original: string, output: string): { valid: boolean; reason?: string } {
    // Check for English ratio (more than 10% English = invalid)
    const englishChars = (output.match(/[a-zA-Z]/g) || []).length;
    const koreanChars = (output.match(/[\uAC00-\uD7AF]/g) || []).length;
    const englishRatio = englishChars / (koreanChars + englishChars + 1);

    if (englishRatio > 0.1) {
        return { valid: false, reason: `English ratio too high: ${(englishRatio * 100).toFixed(1)}%` };
    }

    // Check length (should be within 10% of original, not too short)
    const lengthRatio = output.length / original.length;
    if (lengthRatio < 0.5) {
        return { valid: false, reason: `Output too short: ${(lengthRatio * 100).toFixed(1)}% of original` };
    }

    return { valid: true };
}

// Stage 1: Convert press release to news article (Korean prompt)
// retryCount: 0 = first attempt, 1+ = retry with stricter rules
async function convertToNews(pressRelease: string, retryCount: number = 0): Promise<{ content: string; subtitle: string }> {
    const inputLength = pressRelease.length;
    const minLength = Math.floor(inputLength * 0.9);
    const maxLength = Math.floor(inputLength * 1.1);

    // Ultra-strict Korean-only prompt (reinforced version)
    const prompt = `[ì‹œìŠ¤í…œ ì—­í• ]
ë„ˆëŠ” ëŒ€í•œë¯¼êµ­ ì§€ì—­ ë‰´ìŠ¤ ì „ë¬¸ í¸ì§‘ìë‹¤.
ë³´ë„ìë£Œë¥¼ ë‰´ìŠ¤ ê¸°ì‚¬ë¡œ í¸ì§‘í•˜ëŠ” ê²ƒì´ ì„ë¬´ë‹¤.

##################################################
##  ğŸš¨ğŸš¨ğŸš¨ ì ˆëŒ€ ìœ„ë°˜ ê¸ˆì§€ ê·œì¹™ (P0) ğŸš¨ğŸš¨ğŸš¨  ##
##################################################

1. ì–¸ì–´: ì˜¤ì§ í•œêµ­ì–´ë§Œ ì‚¬ìš©
   - ì˜ì–´ ë‹¨ì–´ 1ê°œë¼ë„ ì‚¬ìš© ê¸ˆì§€
   - "the", "a", "is", "are" ë“± ì˜ì–´ ì ˆëŒ€ ë¶ˆê°€
   - ì˜ì–´ ì•½ì–´ë„ í•œê¸€ë¡œ: CEOâ†’ëŒ€í‘œ, AIâ†’ì¸ê³µì§€ëŠ¥, ITâ†’ì •ë³´ê¸°ìˆ 
   - ìœ„ë°˜ì‹œ: ì¶œë ¥ íê¸° í›„ ì¬ìƒì„±

2. ê¸¸ì´: ì›ë¬¸ ê¸¸ì´ ìœ ì§€ (${minLength}ì ~ ${maxLength}ì)
   - ìš”ì•½ ê¸ˆì§€, ì¶•ì†Œ ê¸ˆì§€, ìƒëµ ê¸ˆì§€
   - ì›ë¬¸ì˜ ëª¨ë“  ë¬¸ë‹¨, ëª¨ë“  ì •ë³´ í¬í•¨ í•„ìˆ˜
   - ìœ„ë°˜ì‹œ: ì¶œë ¥ íê¸° í›„ ì¬ìƒì„±

3. íŒ©íŠ¸: ì›ë³¸ ì‚¬ì‹¤ 100% ë³´ì¡´
   - ìˆ«ì(ê¸ˆì•¡, ë‚ ì§œ, ìˆ˜ëŸ‰) ê·¸ëŒ€ë¡œ ìœ ì§€
   - ì´ë¦„(ì‚¬ëŒ, ê¸°ê´€, ì§€ì—­) ê·¸ëŒ€ë¡œ ìœ ì§€
   - ìƒˆë¡œìš´ ì •ë³´ ì¶”ê°€ ì ˆëŒ€ ê¸ˆì§€

##################################################
##  í¸ì§‘ ê·œì¹™ (P1)  ##
##################################################

1. ì²« ì¤„ì— ë°˜ë“œì‹œ ë¶€ì œëª© ì‘ì„±:
   [ë¶€ì œëª©: ê¸°ì‚¬ í•µì‹¬ì„ 15ì ì´ë‚´ë¡œ ìš”ì•½]

2. ì˜¤íƒ€, ë„ì–´ì“°ê¸° ì˜¤ë¥˜ ìˆ˜ì •

3. ì‚­ì œ ëŒ€ìƒ (ë¶ˆí•„ìš” ì •ë³´):
   - ë‹´ë‹¹ì ì´ë¦„, ì „í™”ë²ˆí˜¸, ì´ë©”ì¼
   - HTML íƒœê·¸, ì €ì‘ê¶Œ ë¬¸êµ¬
   - "ë¬¸ì˜:", "ë‹´ë‹¹:" ë“± ì—°ë½ì²˜ ì •ë³´

4. ë³´ì¡´ ëŒ€ìƒ (í•„ìˆ˜ ì •ë³´):
   - í–‰ì‚¬ëª…, ì¼ì‹œ, ì¥ì†Œ, ì°¸ì„ì
   - ì˜ˆì‚°, ì§€ì›ê¸ˆ, í†µê³„ ìˆ˜ì¹˜
   - ì¸ìš©ë¬¸, ë°œì–¸ ë‚´ìš©

##################################################
${retryCount > 0 ? `
##  âš ï¸ ì¬ì‹œë„ ${retryCount}íšŒì°¨ - ì´ì „ ì¶œë ¥ ì‹¤íŒ¨ ì´ìœ :  ##
##################################################
- ì˜ì–´ í¬í•¨ ë˜ëŠ” ê¸¸ì´ ë¶€ì¡±ìœ¼ë¡œ ê²€ì¦ ì‹¤íŒ¨
- ì´ë²ˆì—ëŠ” ë°˜ë“œì‹œ:
  * í•œêµ­ì–´ë§Œ ì‚¬ìš© (ì˜ì–´ 0ê°œ)
  * ì›ë¬¸ ê¸¸ì´(${inputLength}ì) ìœ ì§€
  * ì›ë¬¸ ë¬¸ì¥ì„ ìµœëŒ€í•œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
##################################################
` : ''}
##  ì¶œë ¥ í˜•ì‹  ##
##################################################

[ë¶€ì œëª©: (15ì ì´ë‚´ í•µì‹¬ ìš”ì•½)]

(ë³¸ë¬¸ - ì›ë¬¸ ê¸¸ì´ì™€ ë™ì¼í•˜ê²Œ ì‘ì„±)

##################################################
##  ì…ë ¥ ë³´ë„ìë£Œ  ##
##################################################
${pressRelease}

##################################################
##  ì¶œë ¥ ë‰´ìŠ¤ ê¸°ì‚¬ (í•œêµ­ì–´ë§Œ, ${minLength}~${maxLength}ì)  ##
##################################################`;

    const response = await callOllama(prompt);

    // Parse subtitle from response
    const subtitleMatch = response.match(/\[ë¶€ì œëª©:\s*(.+?)\]/);
    const subtitle = subtitleMatch ? subtitleMatch[1].trim() : '';

    // Remove subtitle line from content
    let content = response.replace(/\[ë¶€ì œëª©:\s*.+?\]\n*/g, '').trim();

    // Validate output
    const validation = validateOutput(pressRelease, content);
    if (!validation.valid) {
        console.log(`[Ollama] Output validation failed: ${validation.reason}`);
        throw new Error(`Output validation failed: ${validation.reason}`);
    }

    return { content, subtitle };
}

// Stage 2: Verify facts (hallucination check) - Korean prompt for Korean model
async function verifyFacts(original: string, converted: string): Promise<{ verification: string; hasHallucination: boolean; grade: string }> {
    const prompt = `ë„ˆëŠ” íŒ©íŠ¸ì²´í¬ ì „ë¬¸ê°€ë‹¤. ì›ë³¸ê³¼ ë³€í™˜ëœ ê¸°ì‚¬ë¥¼ ë¹„êµí•˜ì—¬ ì‚¬ì‹¤ê´€ê³„ë¥¼ ê²€ì¦í•´ì¤˜.

ê²€ì¦ í•­ëª©:
1. ìˆ«ì(ê¸ˆì•¡, ë¹„ìœ¨, ìˆ˜ëŸ‰)ê°€ ì›ë³¸ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€
2. ë‚ ì§œê°€ ì›ë³¸ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€
3. ì´ë¦„(ì‚¬ëŒ, ê¸°ê´€)ì´ ì›ë³¸ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€
4. ì›ë³¸ì— ì—†ëŠ” ë‚´ìš©ì´ ì¶”ê°€ë˜ì—ˆëŠ”ì§€

ë°˜ë“œì‹œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì¤˜:
[ê²€ì¦ê²°ê³¼]
- ìˆ«ì ì¼ì¹˜: O ë˜ëŠ” X (ë¶ˆì¼ì¹˜ì‹œ ìƒì„¸ ë‚´ìš©)
- ë‚ ì§œ ì¼ì¹˜: O ë˜ëŠ” X (ë¶ˆì¼ì¹˜ì‹œ ìƒì„¸ ë‚´ìš©)
- ì´ë¦„ ì¼ì¹˜: O ë˜ëŠ” X (ë¶ˆì¼ì¹˜ì‹œ ìƒì„¸ ë‚´ìš©)
- ì¶”ê°€ëœ ë‚´ìš©: ì—†ìŒ ë˜ëŠ” ìˆìŒ (ìˆìœ¼ë©´ ìƒì„¸ ë‚´ìš©)
- ìµœì¢…íŒì •: í†µê³¼ ë˜ëŠ” ìˆ˜ì •í•„ìš”

[ì›ë³¸]
${original}

[ë³€í™˜ëœ ê¸°ì‚¬]
${converted}`;

    const verification = await callOllama(prompt);

    // Determine grade based on Korean verification result
    const hasHallucination = verification.includes('ìˆ˜ì •í•„ìš”') ||
                            verification.includes('ì¶”ê°€ëœ ë‚´ìš©: ìˆìŒ') ||
                            verification.includes('X (') ||
                            verification.includes(': X');

    let grade = 'A';
    if (hasHallucination) {
        if (verification.includes('ìˆ«ì ì¼ì¹˜: X') || verification.includes('ë‚ ì§œ ì¼ì¹˜: X')) {
            grade = 'C'; // Critical fact error
        } else {
            grade = 'B'; // Minor issue
        }
    }

    return { verification, hasHallucination, grade };
}

// Process single article with local Ollama - with retry logic for C/D grades
const MAX_RETRIES = 3;

async function processArticle(article: { id: string; title: string; content: string }): Promise<{
    success: boolean;
    published: boolean;
    grade: string;
    retryCount: number;
    error?: string;
}> {
    let lastGrade = 'D';
    let lastContent = '';
    let lastSubtitle = '';
    let lastVerification = '';

    for (let attempt = 0; attempt < MAX_RETRIES; attempt++) {
        try {
            console.log(`[Ollama] Processing article: ${article.id} - ${article.title?.substring(0, 30)}... (attempt ${attempt + 1}/${MAX_RETRIES})`);

            // Stage 1: Convert to news article (with retry count for stricter prompts)
            const { content: convertedContent, subtitle } = await convertToNews(article.content, attempt);

            if (!convertedContent || convertedContent.length < 100) {
                console.log(`[Ollama] Attempt ${attempt + 1}: Content too short, retrying...`);
                continue;
            }

            // Stage 2: Verify facts
            const { grade, hasHallucination, verification } = await verifyFacts(article.content, convertedContent);

            console.log(`[Ollama] Article ${article.id} attempt ${attempt + 1}: Grade ${grade}, Hallucination: ${hasHallucination}`);

            lastGrade = grade;
            lastContent = convertedContent;
            lastSubtitle = subtitle;
            lastVerification = verification;

            // If passed (A or B), break and publish
            if (grade === 'A' || grade === 'B') {
                console.log(`[Ollama] Article ${article.id}: PASSED on attempt ${attempt + 1}`);
                break;
            }

            // If C/D grade and more retries available, continue
            if (attempt < MAX_RETRIES - 1) {
                console.log(`[Ollama] Article ${article.id}: Grade ${grade}, retrying with stricter prompt...`);
                await new Promise(resolve => setTimeout(resolve, 500)); // Small delay between retries
            }

        } catch (err) {
            const errorMessage = err instanceof Error ? err.message : 'Unknown error';
            console.error(`[Ollama] Error on attempt ${attempt + 1} for ${article.id}:`, errorMessage);

            if (attempt === MAX_RETRIES - 1) {
                // Last attempt failed
                await supabaseAdmin
                    .from('posts')
                    .update({
                        ai_processed: true,
                        ai_processed_at: new Date().toISOString(),
                        ai_validation_grade: 'D',
                        ai_validation_warnings: [`Processing error after ${MAX_RETRIES} attempts: ${errorMessage}`]
                    })
                    .eq('id', article.id);

                return {
                    success: false,
                    published: false,
                    grade: 'D',
                    retryCount: attempt + 1,
                    error: errorMessage
                };
            }
        }
    }

    // After all attempts, save the best result
    const shouldPublish = lastGrade === 'A' || lastGrade === 'B';
    const now = new Date().toISOString();

    const updateData: Record<string, unknown> = {
        ai_processed: true,
        ai_processed_at: now,
        ai_validation_grade: lastGrade,
        ai_validation_warnings: shouldPublish ? null : [lastVerification],
    };

    if (shouldPublish) {
        // Grade A/B: Update content, subtitle and publish
        updateData.content = lastContent;
        updateData.subtitle = lastSubtitle || '';
        updateData.status = 'published';
        updateData.published_at = now;
        updateData.site_published_at = now;
        console.log(`[Ollama] Article ${article.id}: PUBLISHED with grade ${lastGrade}`);
    } else {
        // Grade C/D after all retries: Keep original, hold as draft
        updateData.status = 'draft';
        console.log(`[Ollama] Article ${article.id}: HELD with grade ${lastGrade} after ${MAX_RETRIES} attempts`);
    }

    const { error: updateError } = await supabaseAdmin
        .from('posts')
        .update(updateData)
        .eq('id', article.id);

    if (updateError) {
        console.error(`[Ollama] DB update failed for ${article.id}:`, updateError.message);
        return {
            success: false,
            published: false,
            grade: lastGrade,
            retryCount: MAX_RETRIES,
            error: updateError.message
        };
    }

    return {
        success: true,
        published: shouldPublish,
        grade: lastGrade,
        retryCount: MAX_RETRIES
    };
}

// Background processing function (runs async, doesn't block response)
async function runBackgroundProcessing(articles: { id: string; title: string; content: string }[]) {
    let published = 0;
    let held = 0;
    let failed = 0;

    try {
        for (const article of articles) {
            // Check if stop requested
            if (shouldStopProcessing) {
                console.log('[run-ai-processing] Stop requested, halting processing...');
                break;
            }

            const result = await processArticle(article);

            processingStats.processed++;
            if (result.success) {
                if (result.published) {
                    published++;
                    processingStats.published++;
                } else {
                    held++;
                    processingStats.held++;
                }
            } else {
                failed++;
                processingStats.failed++;
            }

            // Small delay between articles to prevent overload
            await new Promise(resolve => setTimeout(resolve, 1000));
        }

        console.log(`[run-ai-processing] ${shouldStopProcessing ? 'Stopped' : 'Complete'}: published=${published}, held=${held}, failed=${failed}`);
    } catch (error) {
        console.error('[run-ai-processing] Background processing error:', error);
    } finally {
        isProcessingActive = false;
        shouldStopProcessing = false;
    }
}

// POST: Trigger AI processing on pending articles using local Ollama
// Returns immediately, processing runs in background
export async function POST(req: NextRequest) {
    console.log('[run-ai-processing] POST request received');

    // Parse request body to get limit parameter
    let limit = 10; // Default limit
    try {
        const body = await req.json();
        if (body.limit && typeof body.limit === 'number' && body.limit > 0) {
            limit = Math.min(body.limit, 100); // Cap at 100 max
        }
        console.log(`[run-ai-processing] Limit: ${limit} articles`);
    } catch {
        // No body or invalid JSON, use default limit
        console.log('[run-ai-processing] No limit specified, using default: 10');
    }

    // If already processing, return current status
    if (isProcessingActive) {
        return NextResponse.json({
            success: false,
            error: 'Processing already in progress',
            stats: processingStats
        }, { status: 409 });
    }

    console.log(`[run-ai-processing] Using Ollama at ${OLLAMA_BASE_URL} with primary model ${PRIMARY_MODEL}`);

    try {
        // Ensure Ollama is running (with retry logic)
        console.log('[run-ai-processing] Ensuring Ollama is running...');
        const ollamaResult = await ensureOllamaRunning(3);

        if (!ollamaResult.success) {
            return NextResponse.json({
                success: false,
                error: `Ollama ì‹œì‘ ì‹¤íŒ¨: ${ollamaResult.message}`,
                hint: 'Ollamaê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. (ollama.com)'
            }, { status: 503 });
        }

        console.log('[run-ai-processing] Ollama is ready, fetching pending articles...');

        // Step 1: Get pending articles with limit applied
        // Split limit between unprocessed and failed articles (prioritize unprocessed)
        const unprocessedLimit = Math.ceil(limit * 0.7); // 70% for unprocessed
        const failedLimit = Math.floor(limit * 0.3);      // 30% for retry

        const { data: unprocessed, error: err1 } = await supabaseAdmin
            .from('posts')
            .select('id, title, content, region')
            .eq('status', 'draft')
            .or('ai_processed.is.null,ai_processed.eq.false')
            .order('created_at', { ascending: true })
            .limit(unprocessedLimit);

        if (err1) throw err1;

        // Get C/D grade articles for retry (only if we have room)
        let failedArticles: typeof unprocessed = [];
        if (failedLimit > 0) {
            const { data: failed, error: err2 } = await supabaseAdmin
                .from('posts')
                .select('id, title, content, region')
                .eq('status', 'draft')
                .eq('ai_processed', true)
                .in('ai_validation_grade', ['C', 'D'])
                .order('created_at', { ascending: true })
                .limit(failedLimit);

            if (err2) throw err2;
            failedArticles = failed || [];
        }

        // Combine and dedupe, then apply final limit
        const allArticles = [...(unprocessed || []), ...failedArticles];
        const articles = allArticles
            .filter((article, index, self) =>
                index === self.findIndex(a => a.id === article.id)
            )
            .slice(0, limit); // Final safety limit

        console.log(`[run-ai-processing] Found ${unprocessed?.length || 0} unprocessed + ${failedArticles?.length || 0} C/D grade articles (limit: ${limit})`);

        if (!articles || articles.length === 0) {
            return NextResponse.json({
                success: true,
                message: 'No pending articles to process',
                total: 0
            });
        }

        console.log(`[run-ai-processing] Starting background processing for ${articles.length} articles`);

        // Initialize global stats
        isProcessingActive = true;
        shouldStopProcessing = false;
        processingStats = {
            total: articles.length,
            processed: 0,
            published: 0,
            held: 0,
            failed: 0,
            startedAt: new Date().toISOString()
        };

        // Start background processing (don't await - returns immediately)
        runBackgroundProcessing(articles);

        // Return immediately with "started" response
        return NextResponse.json({
            success: true,
            message: `Processing started for ${articles.length} articles`,
            total: articles.length,
            stats: processingStats
        });

    } catch (error: unknown) {
        isProcessingActive = false;
        shouldStopProcessing = false;
        const errorMessage = error instanceof Error ? error.message : 'Unknown error';
        console.error('[run-ai-processing] Error:', errorMessage);
        return NextResponse.json(
            { success: false, error: errorMessage },
            { status: 500 }
        );
    }
}

// GET: Check processing status
export async function GET() {
    return NextResponse.json({
        isActive: isProcessingActive,
        stats: processingStats
    });
}

// DELETE: Stop processing
export async function DELETE() {
    if (!isProcessingActive) {
        return NextResponse.json({
            success: false,
            message: 'No active processing to stop'
        });
    }

    shouldStopProcessing = true;
    console.log('[run-ai-processing] Stop signal sent');

    return NextResponse.json({
        success: true,
        message: 'Stop signal sent. Processing will halt after current article.'
    });
}
