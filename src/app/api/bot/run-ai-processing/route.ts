import { NextRequest, NextResponse } from 'next/server';
import { createClient } from '@supabase/supabase-js';
import { spawn } from 'child_process';
import os from 'os';
import { autoAssignReporter, getAutoAssignSetting, type AssignResult } from '@/lib/auto-assign';

const isWindows = os.platform() === 'win32';

// Global state for processing control (toggle)
let isProcessingActive = false;
let shouldStopProcessing = false;
let processingStats = {
    total: 0,
    processed: 0,
    published: 0,
    held: 0,
    failed: 0,
    startedAt: null as string | null,
    lastArticle: null as { title: string; grade: string; status: 'published' | 'held' | 'failed' } | null
};

const supabaseAdmin = createClient(
    process.env.NEXT_PUBLIC_SUPABASE_URL!,
    process.env.SUPABASE_SERVICE_ROLE_KEY!
);

// Local Ollama configuration - Linkbricks Korean 8B (Grade A verified, 105s)
const OLLAMA_BASE_URL = process.env.OLLAMA_BASE_URL || 'http://localhost:11434';
const PRIMARY_MODEL = 'benedict/linkbricks-llama3.1-korean:8b';  // Grade A verified, Korean-focused
const FALLBACK_MODEL = 'solar:10.7b';     // Fallback (bilingual but reliable)

// Ollama API settings - Korean model optimized parameters
const NUM_CTX = 4096;             // Reduced from 8192 (Korean KV cache optimization)
const NUM_PREDICT = 2048;         // Reduced from 4096
const API_TIMEOUT_MS = 180000;    // 3 minutes (Korean models faster with optimized settings)

// Start Ollama directly (no API endpoint dependency - fixes port mismatch issue)
async function ensureOllamaRunning(maxRetries: number = 3): Promise<{ success: boolean; message: string }> {
    console.log('[Ollama] Ensuring Ollama is running...');

    // First check if already running
    try {
        const healthCheck = await fetch(`${OLLAMA_BASE_URL}/api/tags`, {
            signal: AbortSignal.timeout(3000)
        });
        if (healthCheck.ok) {
            console.log('[Ollama] Already running and healthy');
            return { success: true, message: 'Ollama already running' };
        }
    } catch {
        console.log('[Ollama] Not running, attempting to start directly...');
    }

    // Try to start Ollama directly (not via API - fixes port mismatch when dev server uses different port)
    for (let attempt = 1; attempt <= maxRetries; attempt++) {
        try {
            console.log(`[Ollama] Direct start attempt ${attempt}/${maxRetries}...`);

            // Spawn Ollama serve directly
            if (isWindows) {
                const ollamaProcess = spawn('powershell', [
                    '-WindowStyle', 'Hidden',
                    '-Command', 'Start-Process -FilePath ollama -ArgumentList serve -WindowStyle Hidden'
                ], {
                    detached: true,
                    stdio: 'ignore',
                    windowsHide: true
                });
                ollamaProcess.unref();
            } else {
                const ollamaProcess = spawn('ollama', ['serve'], {
                    shell: true,
                    detached: true,
                    stdio: 'ignore'
                });
                ollamaProcess.unref();
            }

            // Wait for Ollama to be ready (poll health endpoint)
            const maxWaitTime = 15000; // 15 seconds
            const startTime = Date.now();
            let lastError = '';

            while (Date.now() - startTime < maxWaitTime) {
                try {
                    const healthCheck = await fetch(`${OLLAMA_BASE_URL}/api/tags`, {
                        signal: AbortSignal.timeout(2000)
                    });
                    if (healthCheck.ok) {
                        console.log('[Ollama] Started successfully (direct spawn)');
                        return { success: true, message: 'Ollama started' };
                    }
                    lastError = `HTTP ${healthCheck.status}`;
                } catch (e) {
                    lastError = e instanceof Error ? e.message : 'Connection refused';
                }
                await new Promise(resolve => setTimeout(resolve, 1000));
            }

            console.log(`[Ollama] Start attempt ${attempt} timeout after ${maxWaitTime/1000}s: ${lastError}`);

        } catch (error) {
            const message = error instanceof Error ? error.message : 'Unknown error';
            console.log(`[Ollama] Start attempt ${attempt} error: ${message}`);
        }

        // Wait before retry (increasing delay)
        if (attempt < maxRetries) {
            const delay = attempt * 2000; // 2s, 4s
            console.log(`[Ollama] Waiting ${delay / 1000}s before retry...`);
            await new Promise(resolve => setTimeout(resolve, delay));
        }
    }

    return { success: false, message: `Failed to start Ollama after ${maxRetries} attempts` };
}

// Call local Ollama API with timeout and expert-recommended parameters
async function callOllama(prompt: string, model: string = PRIMARY_MODEL): Promise<string> {
    const controller = new AbortController();
    const timeoutId = setTimeout(() => controller.abort(), API_TIMEOUT_MS);

    try {
        console.log(`[Ollama] Calling ${model}...`);
        const startTime = Date.now();

        const response = await fetch(`${OLLAMA_BASE_URL}/api/generate`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                model: model,
                prompt: prompt,
                stream: false,
                options: {
                    num_ctx: NUM_CTX,
                    num_predict: NUM_PREDICT,
                    temperature: 0.35,      // Expert: balanced output
                    top_p: 0.9,
                    repeat_penalty: 1.02,   // Expert: lowered to preserve length
                    num_gpu: 32,            // GPU layers limit for Korean models
                    gpu_layers: 32          // Prevent VRAM overflow on RTX 4070 12GB
                }
            }),
            signal: controller.signal
        });

        clearTimeout(timeoutId);
        const elapsed = ((Date.now() - startTime) / 1000).toFixed(1);

        if (!response.ok) {
            throw new Error(`Ollama API error: ${response.status}`);
        }

        const data = await response.json();
        console.log(`[Ollama] Response in ${elapsed}s, output: ${(data.response || '').length} chars`);
        return data.response || '';
    } catch (error: unknown) {
        clearTimeout(timeoutId);
        if (error instanceof Error && error.name === 'AbortError') {
            throw new Error(`Ollama API timeout after ${API_TIMEOUT_MS / 1000}s`);
        }
        throw error;
    }
}

// Validate output: check for English ratio and length
// ì›ë¬¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ (ìˆ«ì, ê³ ìœ ëª…ì‚¬, ì£¼ìš” ëª…ì‚¬)
function extractKeywords(text: string): string[] {
    const keywords: string[] = [];

    // 1. ìˆ«ì í¬í•¨ í‘œí˜„ (ì—°ë„, ê¸ˆì•¡, í¼ì„¼íŠ¸ ë“±)
    const numbers = text.match(/\d+(?:,\d{3})*(?:\.\d+)?(?:ì›|ì–µ|ë§Œ|%|ë…„|ì›”|ì¼|ê°œ|ëª…|ê±´)?/g) || [];
    keywords.push(...numbers);

    // 2. í°ë”°ì˜´í‘œ ì•ˆì˜ ë¬¸êµ¬ (ì¸ìš©ë¬¸, ê³ ìœ ëª…ì‚¬)
    const quoted = text.match(/["'ã€Œã€ã€ã€]([^"'ã€Œã€ã€ã€]+)["'ã€Œã€ã€ã€]/g) || [];
    quoted.forEach(q => {
        const clean = q.replace(/["'ã€Œã€ã€ã€]/g, '').trim();
        if (clean.length >= 2) keywords.push(clean);
    });

    // 3. ê¸°ê´€/ë‹¨ì²´ëª… íŒ¨í„´ (OOë¶€, OOì²­, OOì›, OOì‹œ, OOë„ ë“±)
    const orgs = text.match(/[ê°€-í£]{2,10}(?:ë¶€|ì²­|ì›|ì²˜|ìœ„ì›íšŒ|ê³µì‚¬|ê³µë‹¨|í˜‘íšŒ|ì—°êµ¬ì›|ì§„í¥ì›|ì¬ë‹¨|ì„¼í„°)/g) || [];
    keywords.push(...orgs);

    // 4. ì§€ì—­ëª…
    const regions = text.match(/(?:ì„œìš¸|ë¶€ì‚°|ëŒ€êµ¬|ì¸ì²œ|ê´‘ì£¼|ëŒ€ì „|ìš¸ì‚°|ì„¸ì¢…|ê²½ê¸°|ê°•ì›|ì¶©ë¶|ì¶©ë‚¨|ì „ë¶|ì „ë‚¨|ê²½ë¶|ê²½ë‚¨|ì œì£¼)(?:ì‹œ|ë„|íŠ¹ë³„ì‹œ|ê´‘ì—­ì‹œ)?/g) || [];
    keywords.push(...regions);

    // 5. ì£¼ìš” ëª…ì‚¬ (2-6ê¸€ì í•œê¸€ ë‹¨ì–´)
    const nouns = text.match(/[ê°€-í£]{2,6}(?=ì´|ê°€|ì„|ë¥¼|ì€|ëŠ”|ì—|ì˜|ë¡œ|ìœ¼ë¡œ|ê³¼|ì™€|ë„|ë§Œ|ë¶€í„°|ê¹Œì§€|ì—ì„œ)/g) || [];
    keywords.push(...nouns.filter(n => n.length >= 3));

    // ì¤‘ë³µ ì œê±° ë° ë„ˆë¬´ ì¼ë°˜ì ì¸ ë‹¨ì–´ í•„í„°ë§
    const commonWords = new Set(['í•˜ëŠ”', 'ìˆëŠ”', 'ìœ„í•œ', 'ëŒ€í•œ', 'ê´€ë ¨', 'í†µí•´', 'ë”°ë¼', 'ìœ„í•´', 'ìˆë‹¤', 'í–ˆë‹¤', 'ëœë‹¤', 'í•œë‹¤']);
    const uniqueKeywords = [...new Set(keywords)].filter(k => !commonWords.has(k) && k.length >= 2);

    return uniqueKeywords;
}

function validateOutput(original: string, output: string): { valid: boolean; reason?: string } {
    // Check for English ratio (more than 10% English = invalid)
    const englishChars = (output.match(/[a-zA-Z]/g) || []).length;
    const koreanChars = (output.match(/[\uAC00-\uD7AF]/g) || []).length;
    const englishRatio = englishChars / (koreanChars + englishChars + 1);

    if (englishRatio > 0.1) {
        return { valid: false, reason: `English ratio too high: ${(englishRatio * 100).toFixed(1)}%` };
    }

    // Check length (should be within 10% of original, not too short)
    const lengthRatio = output.length / original.length;
    if (lengthRatio < 0.5) {
        return { valid: false, reason: `Output too short: ${(lengthRatio * 100).toFixed(1)}% of original` };
    }

    // â˜… í•µì‹¬ì–´ ì¼ì¹˜ ê²€ì¦ (í™˜ê° ë°©ì§€)
    const originalKeywords = extractKeywords(original);
    if (originalKeywords.length >= 3) {
        const matchedKeywords = originalKeywords.filter(kw => output.includes(kw));
        const matchRatio = matchedKeywords.length / originalKeywords.length;

        // ìµœì†Œ 30% ì´ìƒì˜ í•µì‹¬ì–´ê°€ ì¶œë ¥ì— í¬í•¨ë˜ì–´ì•¼ í•¨
        if (matchRatio < 0.3) {
            console.log(`[validateOutput] í‚¤ì›Œë“œ ë¶ˆì¼ì¹˜: ${matchedKeywords.length}/${originalKeywords.length} (${(matchRatio * 100).toFixed(1)}%)`);
            console.log(`[validateOutput] ì›ë¬¸ í‚¤ì›Œë“œ ìƒ˜í”Œ: ${originalKeywords.slice(0, 10).join(', ')}`);
            console.log(`[validateOutput] ë§¤ì¹­ëœ í‚¤ì›Œë“œ: ${matchedKeywords.slice(0, 10).join(', ')}`);
            return {
                valid: false,
                reason: `í‚¤ì›Œë“œ ë¶ˆì¼ì¹˜: ${matchedKeywords.length}/${originalKeywords.length} (${(matchRatio * 100).toFixed(1)}%) - ìµœì†Œ 30% í•„ìš”`
            };
        }

        console.log(`[validateOutput] í‚¤ì›Œë“œ ê²€ì¦ í†µê³¼: ${matchedKeywords.length}/${originalKeywords.length} (${(matchRatio * 100).toFixed(1)}%)`);
    }

    return { valid: true };
}

// Stage 1: Convert press release to news article (Korean prompt)
// retryCount: 0 = first attempt, 1+ = retry with stricter rules
async function convertToNews(pressRelease: string, retryCount: number = 0): Promise<{ content: string; subtitle: string }> {
    const inputLength = pressRelease.length;
    const minLength = Math.floor(inputLength * 0.9);
    const maxLength = Math.floor(inputLength * 1.1);

    // Ultra-strict Korean-only prompt (reinforced version)
    const prompt = `[ì‹œìŠ¤í…œ ì—­í• ]
ë„ˆëŠ” ëŒ€í•œë¯¼êµ­ ì§€ì—­ ë‰´ìŠ¤ ì „ë¬¸ í¸ì§‘ìë‹¤.
ë³´ë„ìë£Œë¥¼ ë‰´ìŠ¤ ê¸°ì‚¬ë¡œ í¸ì§‘í•˜ëŠ” ê²ƒì´ ì„ë¬´ë‹¤.

##################################################
##  ğŸš¨ğŸš¨ğŸš¨ ì ˆëŒ€ ìœ„ë°˜ ê¸ˆì§€ ê·œì¹™ (P0) ğŸš¨ğŸš¨ğŸš¨  ##
##################################################

1. ì–¸ì–´: ì˜¤ì§ í•œêµ­ì–´ë§Œ ì‚¬ìš©
   - ì˜ì–´ ë‹¨ì–´ 1ê°œë¼ë„ ì‚¬ìš© ê¸ˆì§€
   - "the", "a", "is", "are" ë“± ì˜ì–´ ì ˆëŒ€ ë¶ˆê°€
   - ì˜ì–´ ì•½ì–´ë„ í•œê¸€ë¡œ: CEOâ†’ëŒ€í‘œ, AIâ†’ì¸ê³µì§€ëŠ¥, ITâ†’ì •ë³´ê¸°ìˆ 
   - ìœ„ë°˜ì‹œ: ì¶œë ¥ íê¸° í›„ ì¬ìƒì„±

2. ê¸¸ì´: ì›ë¬¸ ê¸¸ì´ ìœ ì§€ (${minLength}ì ~ ${maxLength}ì)
   - ìš”ì•½ ê¸ˆì§€, ì¶•ì†Œ ê¸ˆì§€, ìƒëµ ê¸ˆì§€
   - ì›ë¬¸ì˜ ëª¨ë“  ë¬¸ë‹¨, ëª¨ë“  ì •ë³´ í¬í•¨ í•„ìˆ˜
   - ìœ„ë°˜ì‹œ: ì¶œë ¥ íê¸° í›„ ì¬ìƒì„±

3. íŒ©íŠ¸: ì›ë³¸ ì‚¬ì‹¤ 100% ë³´ì¡´
   - ìˆ«ì(ê¸ˆì•¡, ë‚ ì§œ, ìˆ˜ëŸ‰) ê·¸ëŒ€ë¡œ ìœ ì§€
   - ì´ë¦„(ì‚¬ëŒ, ê¸°ê´€, ì§€ì—­) ê·¸ëŒ€ë¡œ ìœ ì§€
   - ìƒˆë¡œìš´ ì •ë³´ ì¶”ê°€ ì ˆëŒ€ ê¸ˆì§€

##################################################
##  í¸ì§‘ ê·œì¹™ (P1)  ##
##################################################

1. ì²« ì¤„ì— ë°˜ë“œì‹œ ë¶€ì œëª© ì‘ì„±:
   [ë¶€ì œëª©: ê¸°ì‚¬ í•µì‹¬ì„ 15ì ì´ë‚´ë¡œ ìš”ì•½]

2. ì˜¤íƒ€, ë„ì–´ì“°ê¸° ì˜¤ë¥˜ ìˆ˜ì •

3. ì‚­ì œ ëŒ€ìƒ (ë¶ˆí•„ìš” ì •ë³´):
   - ë‹´ë‹¹ì ì´ë¦„, ì „í™”ë²ˆí˜¸, ì´ë©”ì¼
   - HTML íƒœê·¸, ì €ì‘ê¶Œ ë¬¸êµ¬
   - "ë¬¸ì˜:", "ë‹´ë‹¹:" ë“± ì—°ë½ì²˜ ì •ë³´

4. ë³´ì¡´ ëŒ€ìƒ (í•„ìˆ˜ ì •ë³´):
   - í–‰ì‚¬ëª…, ì¼ì‹œ, ì¥ì†Œ, ì°¸ì„ì
   - ì˜ˆì‚°, ì§€ì›ê¸ˆ, í†µê³„ ìˆ˜ì¹˜
   - ì¸ìš©ë¬¸, ë°œì–¸ ë‚´ìš©

##################################################
${retryCount > 0 ? `
##  âš ï¸ ì¬ì‹œë„ ${retryCount}íšŒì°¨ - ì´ì „ ì¶œë ¥ ì‹¤íŒ¨ ì´ìœ :  ##
##################################################
- ì˜ì–´ í¬í•¨ ë˜ëŠ” ê¸¸ì´ ë¶€ì¡±ìœ¼ë¡œ ê²€ì¦ ì‹¤íŒ¨
- ì´ë²ˆì—ëŠ” ë°˜ë“œì‹œ:
  * í•œêµ­ì–´ë§Œ ì‚¬ìš© (ì˜ì–´ 0ê°œ)
  * ì›ë¬¸ ê¸¸ì´(${inputLength}ì) ìœ ì§€
  * ì›ë¬¸ ë¬¸ì¥ì„ ìµœëŒ€í•œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
##################################################
` : ''}
##  ì¶œë ¥ í˜•ì‹  ##
##################################################

[ë¶€ì œëª©: (15ì ì´ë‚´ í•µì‹¬ ìš”ì•½)]

(ë³¸ë¬¸ - ì›ë¬¸ ê¸¸ì´ì™€ ë™ì¼í•˜ê²Œ ì‘ì„±)

##################################################
##  ì…ë ¥ ë³´ë„ìë£Œ  ##
##################################################
${pressRelease}

##################################################
##  ì¶œë ¥ ë‰´ìŠ¤ ê¸°ì‚¬ (í•œêµ­ì–´ë§Œ, ${minLength}~${maxLength}ì)  ##
##################################################`;

    const response = await callOllama(prompt);

    // Parse subtitle from response
    const subtitleMatch = response.match(/\[ë¶€ì œëª©:\s*(.+?)\]/);
    const subtitle = subtitleMatch ? subtitleMatch[1].trim() : '';

    // Remove subtitle line from content
    let content = response.replace(/\[ë¶€ì œëª©:\s*.+?\]\n*/g, '').trim();

    // Validate output
    const validation = validateOutput(pressRelease, content);
    if (!validation.valid) {
        console.log(`[Ollama] Output validation failed: ${validation.reason}`);
        throw new Error(`Output validation failed: ${validation.reason}`);
    }

    return { content, subtitle };
}

// Stage 2: Verify facts (hallucination check) - Korean prompt for Korean model
async function verifyFacts(original: string, converted: string): Promise<{ verification: string; hasHallucination: boolean; grade: string }> {
    const prompt = `ë„ˆëŠ” íŒ©íŠ¸ì²´í¬ ì „ë¬¸ê°€ë‹¤. ì›ë³¸ê³¼ ë³€í™˜ëœ ê¸°ì‚¬ë¥¼ ë¹„êµí•˜ì—¬ ì‚¬ì‹¤ê´€ê³„ë¥¼ ê²€ì¦í•´ì¤˜.

ê²€ì¦ í•­ëª©:
1. ìˆ«ì(ê¸ˆì•¡, ë¹„ìœ¨, ìˆ˜ëŸ‰)ê°€ ì›ë³¸ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€
2. ë‚ ì§œê°€ ì›ë³¸ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€
3. ì´ë¦„(ì‚¬ëŒ, ê¸°ê´€)ì´ ì›ë³¸ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€
4. ì›ë³¸ì— ì—†ëŠ” ë‚´ìš©ì´ ì¶”ê°€ë˜ì—ˆëŠ”ì§€

ë°˜ë“œì‹œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì¤˜:
[ê²€ì¦ê²°ê³¼]
- ìˆ«ì ì¼ì¹˜: O ë˜ëŠ” X (ë¶ˆì¼ì¹˜ì‹œ ìƒì„¸ ë‚´ìš©)
- ë‚ ì§œ ì¼ì¹˜: O ë˜ëŠ” X (ë¶ˆì¼ì¹˜ì‹œ ìƒì„¸ ë‚´ìš©)
- ì´ë¦„ ì¼ì¹˜: O ë˜ëŠ” X (ë¶ˆì¼ì¹˜ì‹œ ìƒì„¸ ë‚´ìš©)
- ì¶”ê°€ëœ ë‚´ìš©: ì—†ìŒ ë˜ëŠ” ìˆìŒ (ìˆìœ¼ë©´ ìƒì„¸ ë‚´ìš©)
- ìµœì¢…íŒì •: í†µê³¼ ë˜ëŠ” ìˆ˜ì •í•„ìš”

[ì›ë³¸]
${original}

[ë³€í™˜ëœ ê¸°ì‚¬]
${converted}`;

    const verification = await callOllama(prompt);

    // Determine grade based on Korean verification result
    const hasHallucination = verification.includes('ìˆ˜ì •í•„ìš”') ||
                            verification.includes('ì¶”ê°€ëœ ë‚´ìš©: ìˆìŒ') ||
                            verification.includes('X (') ||
                            verification.includes(': X');

    let grade = 'A';
    if (hasHallucination) {
        if (verification.includes('ìˆ«ì ì¼ì¹˜: X') || verification.includes('ë‚ ì§œ ì¼ì¹˜: X')) {
            grade = 'C'; // Critical fact error
        } else {
            grade = 'B'; // Minor issue
        }
    }

    return { verification, hasHallucination, grade };
}

// Process single article with local Ollama - with retry logic for C/D grades
const MAX_RETRIES = 3;

// useFallbackMode: if true, skip ai_* columns in DB updates (for DBs without these columns)
async function processArticle(article: { id: string; title: string; content: string; region?: string | null }, useFallbackMode: boolean = false): Promise<{
    success: boolean;
    published: boolean;
    grade: string;
    retryCount: number;
    error?: string;
}> {
    let lastGrade = 'D';
    let lastContent = '';
    let lastSubtitle = '';
    let lastVerification = '';

    for (let attempt = 0; attempt < MAX_RETRIES; attempt++) {
        try {
            console.log(`[Ollama] Processing article: ${article.id} - ${article.title?.substring(0, 30)}... (attempt ${attempt + 1}/${MAX_RETRIES})`);

            // Stage 1: Convert to news article (with retry count for stricter prompts)
            const { content: convertedContent, subtitle } = await convertToNews(article.content, attempt);

            if (!convertedContent || convertedContent.length < 100) {
                console.log(`[Ollama] Attempt ${attempt + 1}: Content too short, retrying...`);
                continue;
            }

            // Stage 2: Verify facts
            const { grade, hasHallucination, verification } = await verifyFacts(article.content, convertedContent);

            console.log(`[Ollama] Article ${article.id} attempt ${attempt + 1}: Grade ${grade}, Hallucination: ${hasHallucination}`);

            lastGrade = grade;
            lastContent = convertedContent;
            lastSubtitle = subtitle;
            lastVerification = verification;

            // If passed (A or B), break and publish
            if (grade === 'A' || grade === 'B') {
                console.log(`[Ollama] Article ${article.id}: PASSED on attempt ${attempt + 1}`);
                break;
            }

            // If C/D grade and more retries available, continue
            if (attempt < MAX_RETRIES - 1) {
                console.log(`[Ollama] Article ${article.id}: Grade ${grade}, retrying with stricter prompt...`);
                await new Promise(resolve => setTimeout(resolve, 500)); // Small delay between retries
            }

        } catch (err) {
            const errorMessage = err instanceof Error ? err.message : 'Unknown error';
            console.error(`[Ollama] Error on attempt ${attempt + 1} for ${article.id}:`, errorMessage);

            if (attempt === MAX_RETRIES - 1) {
                // Last attempt failed - update DB (skip ai_* fields in fallback mode)
                const errorUpdateData: Record<string, unknown> = useFallbackMode ? {} : {
                    ai_processed: true,
                    ai_processed_at: new Date().toISOString(),
                    ai_validation_grade: 'D',
                    ai_validation_warnings: [`Processing error after ${MAX_RETRIES} attempts: ${errorMessage}`]
                };

                if (Object.keys(errorUpdateData).length > 0) {
                    await supabaseAdmin
                        .from('posts')
                        .update(errorUpdateData)
                        .eq('id', article.id);
                }

                return {
                    success: false,
                    published: false,
                    grade: 'D',
                    retryCount: attempt + 1,
                    error: errorMessage
                };
            }
        }
    }

    // After all attempts, save the best result
    const shouldPublish = lastGrade === 'A' || lastGrade === 'B';
    const now = new Date().toISOString();

    // Build update data - skip ai_* fields in fallback mode
    const updateData: Record<string, unknown> = {};

    if (!useFallbackMode) {
        updateData.ai_processed = true;
        updateData.ai_processed_at = now;
        updateData.ai_validation_grade = lastGrade;
        updateData.ai_validation_warnings = shouldPublish ? null : [lastVerification];
    }

    if (shouldPublish) {
        // Grade A/B: Update content, subtitle and publish
        updateData.content = lastContent;
        updateData.subtitle = lastSubtitle || '';
        updateData.status = 'published';
        updateData.published_at = now;
        // site_published_at only in normal mode (column may not exist in some DBs)
        if (!useFallbackMode) {
            updateData.site_published_at = now;
        }

        // Auto-assign reporter when publishing
        try {
            const autoAssignEnabled = await getAutoAssignSetting();
            if (autoAssignEnabled) {
                const assignResult: AssignResult = await autoAssignReporter(article.region || null);
                updateData.author_name = assignResult.reporter.name;

                // Verify user_id exists in profiles before setting author_id (FK constraint)
                if (assignResult.reporter.user_id) {
                    const { data: profile, error: profileError } = await supabaseAdmin
                        .from('profiles')
                        .select('id')
                        .eq('id', assignResult.reporter.user_id)
                        .single();

                    if (!profileError && profile) {
                        updateData.author_id = assignResult.reporter.user_id;
                    }
                }

                console.log(`[Ollama] Auto-assigned reporter: ${assignResult.reporter.name} (${assignResult.reason})`);
            }
        } catch (assignError) {
            console.error(`[Ollama] Auto-assign failed for ${article.id}:`, assignError);
            // Continue without auto-assign - don't block the approval
        }

        console.log(`[Ollama] Article ${article.id}: PUBLISHED with grade ${lastGrade}${useFallbackMode ? ' (fallback mode)' : ''}`);
    } else {
        // Grade C/D after all retries: Keep original, hold as draft
        updateData.status = 'draft';
        console.log(`[Ollama] Article ${article.id}: HELD with grade ${lastGrade} after ${MAX_RETRIES} attempts${useFallbackMode ? ' (fallback mode)' : ''}`);
    }

    const { error: updateError } = await supabaseAdmin
        .from('posts')
        .update(updateData)
        .eq('id', article.id);

    if (updateError) {
        console.error(`[Ollama] DB update failed for ${article.id}:`, updateError.message);
        return {
            success: false,
            published: false,
            grade: lastGrade,
            retryCount: MAX_RETRIES,
            error: updateError.message
        };
    }

    return {
        success: true,
        published: shouldPublish,
        grade: lastGrade,
        retryCount: MAX_RETRIES
    };
}

// Background processing function (runs async, doesn't block response)
// Now supports auto-continue: after finishing, checks for more pending articles
// useFallbackMode: if true, skip ai_* columns in queries/updates (for DBs without these columns)
async function runBackgroundProcessing(articles: { id: string; title: string; content: string }[], batchLimit: number = 50, useFallbackMode: boolean = false) {
    let published = 0;
    let held = 0;
    let failed = 0;

    try {
        for (const article of articles) {
            // Check if stop requested
            if (shouldStopProcessing) {
                console.log('[run-ai-processing] Stop requested, halting processing...');
                break;
            }

            const result = await processArticle(article, useFallbackMode);

            processingStats.processed++;

            // Update lastArticle info for status polling
            const articleTitle = article.title || '(ì œëª© ì—†ìŒ)';
            const truncatedTitle = articleTitle.length > 30 ? articleTitle.substring(0, 30) + '...' : articleTitle;

            if (result.success) {
                if (result.published) {
                    published++;
                    processingStats.published++;
                    processingStats.lastArticle = { title: truncatedTitle, grade: result.grade, status: 'published' };
                } else {
                    held++;
                    processingStats.held++;
                    processingStats.lastArticle = { title: truncatedTitle, grade: result.grade, status: 'held' };
                }
            } else {
                failed++;
                processingStats.failed++;
                processingStats.lastArticle = { title: truncatedTitle, grade: result.grade || 'D', status: 'failed' };
            }

            // Small delay between articles to prevent overload
            await new Promise(resolve => setTimeout(resolve, 1000));
        }

        console.log(`[run-ai-processing] ${shouldStopProcessing ? 'Stopped' : 'Complete'}: published=${published}, held=${held}, failed=${failed}`);

        // Auto-continue: Check for more pending articles (only if not stopped)
        if (!shouldStopProcessing) {
            let moreArticles: { id: string; title: string; content: string; region?: string }[] | null = null;

            if (useFallbackMode) {
                // Fallback mode: simple draft query
                const { data, error } = await supabaseAdmin
                    .from('posts')
                    .select('id, title, content, region')
                    .eq('status', 'draft')
                    .order('created_at', { ascending: true })
                    .limit(batchLimit);

                if (!error) moreArticles = data;
            } else {
                // Normal mode: with ai_processed column
                const { data, error } = await supabaseAdmin
                    .from('posts')
                    .select('id, title, content, region')
                    .eq('status', 'draft')
                    .or('ai_processed.is.null,ai_processed.eq.false')
                    .order('created_at', { ascending: true })
                    .limit(batchLimit);

                if (!error) moreArticles = data;
            }

            if (moreArticles && moreArticles.length > 0) {
                console.log(`[run-ai-processing] Auto-continue: Found ${moreArticles.length} more pending articles`);

                // Update stats for new batch (accumulate totals)
                processingStats.total += moreArticles.length;

                // Recursively process the next batch
                await runBackgroundProcessing(moreArticles, batchLimit, useFallbackMode);
                return; // Don't reset isProcessingActive here, let the final batch do it
            } else {
                console.log('[run-ai-processing] Auto-continue: No more pending articles');
            }
        }
    } catch (error) {
        console.error('[run-ai-processing] Background processing error:', error);
    } finally {
        isProcessingActive = false;
        shouldStopProcessing = false;
    }
}

// POST: Trigger AI processing on pending articles using local Ollama
// Returns immediately, processing runs in background
// âš ï¸ AI ì²˜ë¦¬ ì„ì‹œ ë¹„í™œì„±í™” (í™˜ê° ë¬¸ì œë¡œ ì¸í•´ 2026-01-06 ë¹„í™œì„±í™”)
// ì›ì¸: AIê°€ ì…ë ¥ì„ ë¬´ì‹œí•˜ê³  í•™ìŠµ ë°ì´í„° ê¸°ë°˜ í—ˆìœ„ ì½˜í…ì¸  ìƒì„±
// í•´ê²°ì±…: í‚¤ì›Œë“œ ê²€ì¦ ë¡œì§ ì¶”ê°€ í›„ ì¬í™œì„±í™” í•„ìš”
const AI_PROCESSING_DISABLED = true;

export async function POST(req: NextRequest) {
    console.log('[run-ai-processing] POST request received');

    // AI ì²˜ë¦¬ ë¹„í™œì„±í™” ì²´í¬
    if (AI_PROCESSING_DISABLED) {
        console.log('[run-ai-processing] âš ï¸ AI processing is temporarily disabled due to hallucination issues');
        return NextResponse.json({
            success: false,
            error: 'AI ì²˜ë¦¬ ê¸°ëŠ¥ì´ ì„ì‹œë¡œ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤. (í™˜ê° ë¬¸ì œ í•´ê²° ì¤‘)',
            reason: 'AI_DISABLED'
        }, { status: 503 });
    }

    // Parse request body to get limit parameter
    let limit = 10; // Default limit
    try {
        const body = await req.json();
        if (body.limit && typeof body.limit === 'number' && body.limit > 0) {
            limit = Math.min(body.limit, 100); // Cap at 100 max
        }
        console.log(`[run-ai-processing] Limit: ${limit} articles`);
    } catch {
        // No body or invalid JSON, use default limit
        console.log('[run-ai-processing] No limit specified, using default: 10');
    }

    // If already processing, return current status
    if (isProcessingActive) {
        return NextResponse.json({
            success: false,
            error: 'Processing already in progress',
            stats: processingStats
        }, { status: 409 });
    }

    console.log(`[run-ai-processing] Using Ollama at ${OLLAMA_BASE_URL} with primary model ${PRIMARY_MODEL}`);

    try {
        // Ensure Ollama is running (with retry logic)
        console.log('[run-ai-processing] Ensuring Ollama is running...');
        const ollamaResult = await ensureOllamaRunning(3);

        if (!ollamaResult.success) {
            return NextResponse.json({
                success: false,
                error: `Ollama ì‹œì‘ ì‹¤íŒ¨: ${ollamaResult.message}`,
                hint: 'Ollamaê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. (ollama.com)'
            }, { status: 503 });
        }

        console.log('[run-ai-processing] Ollama is ready, fetching pending articles...');

        // Step 1: Get pending articles with limit applied
        // Try complex query first (with ai_processed column), fallback to simple query
        let articles: { id: string; title: string; content: string; region?: string }[] = [];
        let useFallbackMode = false;

        try {
            // Split limit between unprocessed and failed articles (prioritize unprocessed)
            const unprocessedLimit = Math.ceil(limit * 0.7); // 70% for unprocessed
            const failedLimit = Math.floor(limit * 0.3);      // 30% for retry

            const { data: unprocessed, error: err1 } = await supabaseAdmin
                .from('posts')
                .select('id, title, content, region')
                .eq('status', 'draft')
                .or('ai_processed.is.null,ai_processed.eq.false')
                .order('created_at', { ascending: true })
                .limit(unprocessedLimit);

            if (err1) {
                // ai_processed column doesn't exist, use fallback mode
                console.log('[run-ai-processing] Fallback mode: ai_processed column not found');
                useFallbackMode = true;
                throw err1;
            }

            // Get C/D grade articles for retry (only if we have room)
            let failedArticles: typeof unprocessed = [];
            if (failedLimit > 0) {
                const { data: failed, error: err2 } = await supabaseAdmin
                    .from('posts')
                    .select('id, title, content, region')
                    .eq('status', 'draft')
                    .eq('ai_processed', true)
                    .in('ai_validation_grade', ['C', 'D'])
                    .order('created_at', { ascending: true })
                    .limit(failedLimit);

                if (!err2) {
                    failedArticles = failed || [];
                }
            }

            // Combine and dedupe, then apply final limit
            const allArticles = [...(unprocessed || []), ...failedArticles];
            articles = allArticles
                .filter((article, index, self) =>
                    index === self.findIndex(a => a.id === article.id)
                )
                .slice(0, limit); // Final safety limit

            console.log(`[run-ai-processing] Found ${unprocessed?.length || 0} unprocessed + ${failedArticles?.length || 0} C/D grade articles (limit: ${limit})`);

        } catch {
            // Fallback: Simple query without ai_processed column
            console.log('[run-ai-processing] Using simple draft query (fallback mode)');
            useFallbackMode = true;

            const { data: draftArticles, error: fallbackErr } = await supabaseAdmin
                .from('posts')
                .select('id, title, content, region')
                .eq('status', 'draft')
                .order('created_at', { ascending: true })
                .limit(limit);

            if (fallbackErr) throw fallbackErr;
            articles = draftArticles || [];

            console.log(`[run-ai-processing] Fallback: Found ${articles.length} draft articles (limit: ${limit})`);
        }

        if (!articles || articles.length === 0) {
            return NextResponse.json({
                success: true,
                message: 'No pending articles to process',
                total: 0
            });
        }

        console.log(`[run-ai-processing] Starting background processing for ${articles.length} articles`);

        // Initialize global stats
        isProcessingActive = true;
        shouldStopProcessing = false;
        processingStats = {
            total: articles.length,
            processed: 0,
            published: 0,
            held: 0,
            failed: 0,
            startedAt: new Date().toISOString(),
            lastArticle: null
        };

        // Start background processing (don't await - returns immediately)
        // Pass limit for auto-continue batches and fallback mode flag
        runBackgroundProcessing(articles, limit, useFallbackMode);

        // Return immediately with "started" response
        return NextResponse.json({
            success: true,
            message: `Processing started for ${articles.length} articles${useFallbackMode ? ' (fallback mode)' : ''}`,
            total: articles.length,
            fallbackMode: useFallbackMode,
            stats: processingStats
        });

    } catch (error: unknown) {
        isProcessingActive = false;
        shouldStopProcessing = false;
        const errorMessage = error instanceof Error ? error.message : 'Unknown error';
        console.error('[run-ai-processing] Error:', errorMessage);
        return NextResponse.json(
            { success: false, error: errorMessage },
            { status: 500 }
        );
    }
}

// GET: Check processing status
export async function GET() {
    return NextResponse.json({
        isActive: isProcessingActive,
        stats: processingStats
    });
}

// DELETE: Stop processing
export async function DELETE() {
    if (!isProcessingActive) {
        return NextResponse.json({
            success: false,
            message: 'No active processing to stop'
        });
    }

    shouldStopProcessing = true;
    console.log('[run-ai-processing] Stop signal sent');

    return NextResponse.json({
        success: true,
        message: 'Stop signal sent. Processing will halt after current article.'
    });
}
