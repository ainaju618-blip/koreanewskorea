Publishable key
sb_publishable_wIHo_FAp8WN7t4aSlvqgOg_9asFwAvl
Secret keys
sb_secret_LheosgdDksFiVakYI5sBOQ_htCpDdCI
anon NEXT_PUBLIC_SUPABASE_ANON_KEY
eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InhkY3hmYW91Y3Z6ZnJyeWhjem15Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3NjQ4NjA5MjAsImV4cCI6MjA4MDQzNjkyMH0.mc_IQ_CrmR4djs7f7lkI8qHh9p3ozwwJ8tzkreMLask




[PRD: 기술 심화형] 코리아뉴스 AI 데스크 (K-News Intelligence)

1. 시스템 구축 철학 (영상 기반)

Vibe Coding: 처음부터 거창한 시스템을 기획하지 않고, 파이썬 스크립트 하나(MVP)부터 시작해 살을 붙여나간다.

Double Filtering: 구글/네이버 검색 결과를 믿지 않고, 반드시 로컬에서 2차 검증(정규식)을 거친다.

Hybrid AI: 민감한 정보는 로컬 LLM(Ollama)으로, 일반 정보는 클라우드 API(Claude/GPT)로 처리한다.

2. 상세 기술 스택 (Tech Stack)

영상에서 언급된 실제 도구들을 발행인님 상황에 맞춰 최적화했습니다.

구분추천 기술영상 내 근거 및 선정 이유프론트엔드Streamlit (초기) → Next.js (확장)처음엔 파이썬만으로 화면을 구성하는 Streamlit으로 시작하고, 기능이 많아지면 Next.js로 고도화 (영상 13:41, 24:30).백엔드/DBSupabase구글 시트의 한계를 넘어선 후 선택. 무료이며 엑셀처럼 데이터 관리가 가능하고, MCP(Model Context Protocol) 연결이 용이함 (영상 33:57).크롤링Python (Requests + BeautifulSoup)가장 기초적이고 강력한 수집 도구. 동적 페이지는 Selenium 추가.AI 모델Claude 3.5 Sonnet (Skills)한국어 문맥 이해가 뛰어나고, '도구 사용(Skills)' 기능으로 정형 데이터 추출에 유리함 (영상 18:27).로컬 AIOllama (Llama 3)내 노트북에서 AI를 돌려 비용을 아끼고 보안을 유지하는 방식 (영상 04:58).

3. 핵심 기능별 상세 구현 로직 (Technical Logic)

3.1. [심층 취재] '단독' 및 이슈 키워드 이중 필터링 시스템

영상(15:30경)에서 박용규 실장이 "네이버 검색 결과에 노이즈가 너무 많아 2단계로 걸러냈다"고 한 핵심 로직입니다.

목표: 나주/전남 지역의 '단독' 기사 혹은 '특종' 낌새가 있는 기사를 100% 정확도로 포착.

구현 로직 (Step-by-Step):

1차 수집 (Search): 네이버/구글 뉴스 검색 API 혹은 크롤링.

검색어 예시: 나주 "단독", 혁신도시 "단독", 한전 "단독" (쌍따옴표로 정확도 높임)

2차 검증 (Regex Filter): 1차 결과 중 제목에 실제로 [단독], <단독> 태그가 붙어 있는지 **정규표현식(Regex)**으로 검사.

영상 포인트: 본문에 '단독주택' 같은 단어가 있어 검색되는 노이즈를 제거하기 위함.

Python 정규식 예시: ^(?:\[단독\]|\<단독\>|\[Exclusive\]).* (제목 맨 앞에 단독 태그가 있는 경우만 추출)

알림 발송: 검증된 '진짜 단독' 기사만 텔레그램으로 즉시 전송.

3.2. [행정 감시] Claude Skills를 활용한 공고 자동 분류

영상(18:27, 23:24)에서 '오늘의 법안'이나 '보도자료'를 처리할 때 사용한 방식입니다. 단순 크롤링을 넘어 AI에게 **"이 문서를 읽고 판단해"**라고 시키는 기술입니다.

목표: 나주시청 고시공고가 올라오면 단순히 긁어오는 게 아니라, 이것이 '돈(예산)이 되는 정보'인지, '단순 알림'인지 AI가 판단하게 함.

구현 로직 (Claude Skills / Function Calling):

데이터 수집: 나주시청 게시판의 새 글 제목과 본문 텍스트 추출.

Schema 정의: AI에게 답변 형식을 강제함.

JSON



{

  "type": "입찰" | "채용" | "행사" | "기타",

  "importance": "High" | "Medium" | "Low",

  "summary": "한 줄 요약",

  "budget": "관련 예산 금액(있을 경우)"

}

Prompting: "아래 공고문을 읽고 위 JSON 형식에 맞춰 분류해. 특히 '입찰'이나 '주민 의견 청취'는 중요도를 High로 설정해."

DB 저장: AI가 뱉어준 JSON 데이터를 Supabase에 구조화하여 저장.

3.3. [지역 여론] 로컬 LLM(Ollama)을 이용한 맘카페 분석

영상(04:58)에서 내 노트북(로컬)에서 모델을 돌리는 내용을 참고합니다. 민감한 지역 여론이나 비공개 제보 내용을 분석할 때 외부 서버로 데이터를 보내지 않기 위함입니다.

목표: 빛가람 혁신도시 맘카페 등의 게시글 분위기(Sentiment) 분석.

구현 로직:

Ollama 설치: 발행인님 노트북에 Ollama 설치 및 가벼운 한국어 모델(Llama-3-Korean 등) 다운로드.

분석 스크립트:

파이썬 스크립트가 맘카페 '베스트 게시글' 10개의 제목과 내용을 긁어옴.

로컬 API(localhost:11434)로 데이터를 보내 요약 요청.

프롬프트: "이 게시글들에서 나주 시민들이 가장 불만스러워하는 요소 3가지만 키워드로 뽑아줘."

결과: "1. 수돗물 탁수, 2. 불법 주정차, 3. 소아과 대기 시간" 형태로 요약되어 대시보드 출력.

3.4. [데이터 관리] Supabase & MCP 활용

영상(33:57)에서 엑셀(구글 시트) 쓰다가 느려서 Supabase로 넘어간 경험을 반영합니다.

목표: 기사, 공고, 취재원 정보를 체계적으로 관리하고, 나중에 AI가 이 데이터를 검색해서 기사를 쓰게 만듦.

구현 로직:

Supabase 세팅: 회원가입 후 'Table' 생성 (엑셀 시트 만드는 것과 비슷).

테이블 예: naju_news_archive, public_notices, restaurant_menu

Upsert (Update + Insert) 로직:

영상(14:23) 식당 메뉴 업데이트 사례 참고.

데이터를 넣을 때, 기존에 있는 공고번호면 '내용 업데이트'를 하고, 없으면 '새로 추가'하는 로직을 적용해 중복 방지.

RAG (검색 증강 생성) 준비: 추후 "작년 배 축제 예산 얼마였지?"라고 물어보면 AI가 이 DB를 뒤져서 답하도록 pgvector 기능 활성화.

4. 단계별 개발 가이드 (Vibe Coding 방식)

박용규 실장이 했던 것처럼, "일단 돌아가게 만들고(MVP), 나중에 예쁘게 다듬는" 순서입니다.

1단계: 파이썬 스크립트 + 텔레그램 봇 (가장 시급)

할 일: 나주시청 '고시/공고' 게시판 1페이지를 긁어서, 어제 본 글이 아니면 텔레그램으로 제목/링크 전송.

필요 기술: Python requests, BeautifulSoup (정적 페이지 크롤링).

포인트: 서버 살 필요 없습니다. 발행인님 PC에서 스케줄러(윈도우 작업 스케줄러)로 하루 3번 돌리세요.

2단계: '단독' 뉴스 필터링 (정규식 적용)

할 일: 네이버 뉴스 API로 '나주', '한전' 검색 → 파이썬 정규식(re 모듈)으로 제목 검증 → 엑셀(csv) 파일로 저장.

포인트: 1차 검색 결과 100개 중 진짜 필요한 2~3개를 골라내는 정규식 패턴을 정교하게 짜는 것이 핵심.

3단계: 웹 대시보드화 (Streamlit → Next.js)

할 일: 매번 엑셀 파일 열기 귀찮으므로, 웹페이지 형태로 만듦.

도구: Streamlit을 쓰면 파이썬 코드 몇 줄로 웹사이트가 뚝딱 만들어집니다. (영상 초반 박용규 실장 방식)

기능: 수집된 뉴스 목록 보여주기, 클릭하면 AI 3줄 요약 팝업 띄우기.

4단계: AI 기자 도입 (Claude Skills)

할 일: 보도자료 텍스트를 입력하면 기사 초안을 작성해주는 기능.

포인트: 단순히 "기사 써줘"가 아니라, 코리아뉴스 기사 10개를 예시(Few-shot prompting)로 제공하여 "우리 신문사 말투"를 학습시킴.

5. 발행인님을 위한 Action Plan

지금 바로 **Cursor(커서)**나 VS Code를 켜고 AI(ChatGPT/Claude)에게 아래와 같이 명령어를 입력해 보세요. 영상 속 박용규 실장이 했던 방식 그대로입니다.

[프롬프트 예시]

"파이썬으로 나주시청 고시공고 게시판(URL 입력)의 첫 페이지 게시글 제목과 링크를 크롤링하는 코드를 짜줘.

그리고 **정규표현식(Regex)**을 사용해서 제목에 '입찰', '공고', '변경'이라는 단어가 들어간 것만 따로 리스트로 뽑아줘.

마지막으로 이 리스트를 내 텔레그램 봇으로 전송하는 기능까지 추가해줘."

[Gemini's Insight] 코리아뉴스만의 차별화 전략 (B + @)

위의 기술적 토대 위에, **지역 신문(Local News)**으로서의 특색을 살린 저만의 추가 아이디어를 제안합니다. 박용규 실장님이 국회 데이터로 '법안 분석'을 했다면, 코리아뉴스는 '지역 생활 밀착형 데이터'로 승부해야 합니다.

6. 확장 모듈 제안: 나주 특화 AI 서비스

6.1. 나주 배(Pear) & 농산물 경매가 알림봇

아이디어: 나주는 농업 비중이 큽니다. 나주 공판장(또는 aT)의 일일 경매 데이터를 크롤링하여, 전일 대비 가격 등락폭이 큰 농산물 정보를 농민들에게 뉴스레터나 카톡으로 아침마다 자동 발송합니다.

기술 적용: 영상의 '주식/법안 변동' 로직을 농산물 가격에 대입.

가치: 단순 뉴스를 넘어 **'돈이 되는 정보'**를 주는 언론사로 포지셔닝.

6.2. 의회 속기록 RAG (대화형 검색)

아이디어: 나주시 의회 회의록은 양이 방대하여 시민들이 읽지 않습니다. 이를 Supabase(Vector DB)에 저장해두고, 시민들이 챗봇에게 물어볼 수 있게 합니다.

예시 질문: "이번에 혁신도시 주차장 관련해서 시의원이 무슨 발언 했어?"

기술 적용: 영상에서 '국회 법안'을 분석한 것과 동일한 로직. RAG 기술을 통해 '팩트 기반' 답변 제공.

6.3. '우리 동네 민원 지도' 시각화

아이디어: 영상 속 '국회 앞 식당 지도'에서 착안했습니다. 맘카페나 시청 민원 게시판의 데이터를 분석해, 민원이 많이 발생하는 지역을 지도 위에 히트맵(Heatmap)으로 보여줍니다.

활용: "이번 주 빛가람동 최대 불만은 '악취', 구도심은 '쓰레기'"와 같은 기사를 AI가 데이터 기반으로 초안을 잡아줍니다.

요약 및 제언

영상 속 박용규 실장님은 "노트북을 아십니까?"라는 질문으로 AI 활용 능력을 가늠한다고 했습니다. 이는 **'내 로컬 환경(내 컴퓨터)에서 무언가를 직접 돌려보려는 시도'**가 AI 리터러시의 시작점이라는 뜻입니다.

발행인님, 지금 당장 완벽한 앱을 만들려 하지 마십시오.

불편한 것 하나(예: 매일 시청 게시판 들어가기)를 정합니다.

Claude나 GPT에게 "이거 파이썬으로 자동화해줘"라고 묻습니다.

오류가 나면 오류 메시지를 그대로 복사해서 다시 AI에게 묻습니다(끈기).

이 과정을 3일만 반복하시면, 나주에서 가장 앞서가는 'AI 기반 데이터 저널리즘' 언론사가 되어 있을 것입니다. 지금 바로 VS Code를 설치하는 것부터 시작해 보시겠습니까?