"""
Mokpo Stealth Image Capture Test
- Demonstrates capturing images by mimicking browser requests
- Uses Cloudinary for storage
- Limit: 5 articles
"""

import sys
import os
import time
import random
from typing import List, Dict, Optional
from urllib.parse import urljoin

# Add parent directory to path to import utils
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from playwright.sync_api import sync_playwright
from utils.api_client import send_article_to_server, log_to_server
from utils.scraper_utils import wait_and_find, safe_get_text, safe_get_attr
from utils.cloudinary_uploader import download_and_upload_image

REGION_CODE = 'mokpo'
REGION_NAME = 'ëª©í¬ì‹œ'
CATEGORY_NAME = 'ì „ë‚¨'
BASE_URL = 'https://www.mokpo.go.kr'
LIST_URL = 'https://www.mokpo.go.kr/www/mokpo_news/press_release/report_material'

# ëª©í¬ì‹œ ì „ìš© ì…€ë ‰í„° (Copied from mokpo_scraper.py)
LIST_SELECTORS = [
    'a.item_cont',
    '.list_item a',
    'a[href*="view"]',
]

def test_stealth_capture():
    print(f"ğŸ•µï¸ {REGION_NAME} ìŠ¤í…”ìŠ¤ ì´ë¯¸ì§€ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ ì‹œì‘ (ìµœëŒ€ 5ê±´)")
    
    with sync_playwright() as p:
        browser = p.chromium.launch(
            headless=True,
            args=['--disable-blink-features=AutomationControlled']
        )
        context = browser.new_context(
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            viewport={'width': 1280, 'height': 1024}
        )
        page = context.new_page()
        
def test_stealth_capture():
    print(f"ğŸ•µï¸ {REGION_NAME} ìŠ¤í…”ìŠ¤ ì´ë¯¸ì§€ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ ì‹œì‘ (ìµœëŒ€ 5ê±´)")
    
    with sync_playwright() as p:
        browser = p.chromium.launch(
            headless=True,
            args=['--disable-blink-features=AutomationControlled']
        )
        context = browser.new_context(
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            viewport={'width': 1280, 'height': 1024}
        )
        page = context.new_page()
        
        # 1. List Page Access
        print(f"   ğŸ“„ ëª©ë¡ í˜ì´ì§€ ì ‘ê·¼ ì¤‘: {LIST_URL}")
        page.goto(LIST_URL, wait_until='domcontentloaded')
        
        # 2. Get Articles
        rows = wait_and_find(page, LIST_SELECTORS, timeout=10000)
        
        if not rows:
             print("      âš ï¸ íƒ€ì„ì•„ì›ƒ: ê¸°ì‚¬ ëª©ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
             return

        count = rows.count()
        print(f"   ğŸ“° ë°œê²¬ëœ ê¸°ì‚¬: {count}ê°œ (5ê°œë§Œ ìˆ˜ì§‘)")
        
        # 2.1 Collect Links First
        link_data = []
        for i in range(min(count, 5)):
             try:
                row = rows.nth(i)
                title_elem = row.locator('h3')
                if title_elem.count() == 0:
                    title = row.inner_text().strip()
                else:
                    title = title_elem.inner_text().strip()
                
                href = row.get_attribute('href')
                full_url = urljoin(BASE_URL, href)
                link_data.append({'title': title, 'url': full_url})
             except Exception as e:
                print(f"      ë§í¬ ìˆ˜ì§‘ ì¤‘ ì—ëŸ¬: {e}")

        # 3. Process Details
        collected_count = 0
        for item in link_data:
            try:
                title = item['title']
                full_url = item['url']
                print(f"\n   [{collected_count+1}/5] ì²˜ë¦¬ ì¤‘: {title[:20]}...")
                
                # Goto Detail
                page.goto(full_url, wait_until='domcontentloaded')
                time.sleep(random.uniform(1.5, 3.0)) # Human-like pause
                
                # 4. Find Image
                img_selector = ['div.image_viewbox img', 'div.viewbox img', 'div.board_view_cont img']
                container_selector = ['div.viewbox', 'div.module_view_box', 'div.board_view_cont']
                
                thumbnail_url = None # Initialize 
                
                # Use wait_and_find for robustness
                container = wait_and_find(page, container_selector, timeout=5000)
                
                if container:
                    print(f"      ğŸ‘€ ë³¸ë¬¸ ì»¨í…Œì´ë„ˆ ë°œê²¬: {container.evaluate('node => node.className')}")
                    imgs_in_container = container.locator('img')
                    count = imgs_in_container.count()
                    print(f"      ğŸ‘€ ì»¨í…Œì´ë„ˆ ë‚´ ì´ë¯¸ì§€ ê°œìˆ˜: {count}")
                    
                    if count > 0:
                        img_elem = imgs_in_container.first
                        src = img_elem.get_attribute('src')
                        if src and not any(x in src.lower() for x in ['icon', 'btn', 'logo']):
                            original_img_url = urljoin(BASE_URL, src)
                            print(f"      ğŸ“¸ ì´ë¯¸ì§€ ë°œê²¬: {original_img_url[:50]}...")
                            
                            # 5. Stealth Download & Upload
                            print("      â˜ï¸ Cloudinary ì—…ë¡œë“œ ì‹œë„ (Referer Spoofing)...")
                            cloudinary_url = download_and_upload_image(
                                original_img_url, 
                                base_url=full_url, 
                                folder="mokpo_test"
                            )
                            
                            if cloudinary_url:
                                thumbnail_url = cloudinary_url
                                print(f"      âœ… ì—…ë¡œë“œ ì„±ê³µ: {thumbnail_url}")
                            else:
                                print("      âŒ ì—…ë¡œë“œ ì‹¤íŒ¨ (ì›ë³¸ URL ìœ ì§€)")
                                thumbnail_url = original_img_url
                                
                            time.sleep(random.uniform(2, 4))
                else:
                    print(f"      âš ï¸ ë³¸ë¬¸ ì»¨í…Œì´ë„ˆë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (HTML ë¤í”„ ì €ì¥: debug_mokpo.html)")
                    with open('debug_mokpo.html', 'w', encoding='utf-8') as f:
                        f.write(page.content())
                
                # 6. Extract Content
                if container:
                    content = container.inner_text().strip()[:1000]
                else:
                    content = "Content missing"
                
                # 7. Send to Server
                article = {
                   'title': f"[ìŠ¤í…”ìŠ¤ í…ŒìŠ¤íŠ¸] {title}",
                   'content': content,
                   'published_at': time.strftime('%Y-%m-%dT09:00:00+09:00'),
                   'original_link': full_url,
                   'source': REGION_NAME,
                   'category': CATEGORY_NAME,
                   'region': REGION_CODE,
                   'thumbnail_url': thumbnail_url
                }
                
                result = send_article_to_server(article)
                if result.get('status') == 'created':
                    print("      ğŸ’¾ ì„œë²„ ì €ì¥ ì™„ë£Œ")
                else:
                    print(f"      âš ï¸ ì„œë²„ ì €ì¥ ê²°ê³¼: {result.get('status')}")
                    
                collected_count += 1
                
            except Exception as e:
                print(f"      âŒ ì—ëŸ¬ ë°œìƒ: {e}")
                continue
                
        browser.close()
        print(f"\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {collected_count}ê°œ ì²˜ë¦¬ë¨")

def new_date_format(date_str):
    if not date_str: return time.strftime('%Y-%m-%dT09:00:00+09:00')
    try:
        return f"{date_str.replace('.','-').strip()}T09:00:00+09:00"
    except:
        return time.strftime('%Y-%m-%dT09:00:00+09:00')

if __name__ == "__main__":
    test_stealth_capture()
