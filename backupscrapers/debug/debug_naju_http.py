"""
ë‚˜ì£¼ì‹œì²­ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ í…ŒìŠ¤íŠ¸ (HTTP ì§ì ‘ ìš”ì²­)
- og:image URLì´ http:// í”„ë¡œí† ì½œì„ì„ í™•ì¸
- Mixed Content ë¬¸ì œ ìš°íšŒë¥¼ ìœ„í•´ requestsë¡œ ì§ì ‘ ë‹¤ìš´ë¡œë“œ
"""

import os
import requests
from bs4 import BeautifulSoup

BASE_URL = 'https://www.naju.go.kr'
LIST_URL = f'{BASE_URL}/www/administration/reporting/coverage'
SAVE_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'images', 'naju_http')

def test_http_direct():
    print("ğŸš€ HTTP ì§ì ‘ ìš”ì²­ í…ŒìŠ¤íŠ¸ (1ê°œ ê¸°ì‚¬)")
    os.makedirs(SAVE_DIR, exist_ok=True)
    
    session = requests.Session()
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    }
    
    # 1. ëª©ë¡ í˜ì´ì§€ (ì¿ í‚¤ íšë“)
    print("ğŸŒ ëª©ë¡ í˜ì´ì§€ ì ‘ì†...")
    resp = session.get(LIST_URL, headers=headers, timeout=10)
    print(f"   ìƒíƒœ: {resp.status_code}")
    print(f"   ì¿ í‚¤: {dict(session.cookies)}")
    
    # ì²« ë²ˆì§¸ ê¸°ì‚¬ ë§í¬ ì°¾ê¸°
    soup = BeautifulSoup(resp.text, 'html.parser')
    link = soup.select_one('tbody tr a[href*="coverage?idx="]')
    href = BASE_URL + link['href'].replace('&amp;', '&')
    
    print(f"   ìƒì„¸ URL: {href}")
    
    # 2. ìƒì„¸ í˜ì´ì§€ ì ‘ì†
    print("\nâ¡ï¸ ìƒì„¸ í˜ì´ì§€ ì ‘ì†...")
    headers['Referer'] = LIST_URL
    resp = session.get(href, headers=headers, timeout=10)
    print(f"   ìƒíƒœ: {resp.status_code}")
    
    # og:image ì¶”ì¶œ
    soup = BeautifulSoup(resp.text, 'html.parser')
    og_image = soup.find('meta', property='og:image')
    og_image_url = og_image['content'] if og_image else None
    
    print(f"   og:image: {og_image_url}")
    
    if not og_image_url:
        print("   âŒ og:image ì—†ìŒ")
        return
    
    # 3. ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹œë„
    print("\nğŸ“¥ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹œë„...")
    
    # ì›ë³¸ URL (http://)
    print(f"\n   ë°©ë²• 1: ì›ë³¸ HTTP URL")
    headers['Referer'] = href
    headers['Accept'] = 'image/avif,image/webp,image/*,*/*;q=0.8'
    
    try:
        img_resp = session.get(og_image_url, headers=headers, timeout=10)
        print(f"   ìƒíƒœ: {img_resp.status_code}")
        print(f"   Content-Type: {img_resp.headers.get('Content-Type', 'N/A')}")
        print(f"   í¬ê¸°: {len(img_resp.content)} bytes")
        
        if img_resp.status_code == 200 and len(img_resp.content) > 1000:
            filepath = os.path.join(SAVE_DIR, 'test_http.jpg')
            with open(filepath, 'wb') as f:
                f.write(img_resp.content)
            print(f"   âœ… ì„±ê³µ! ì €ì¥: {filepath}")
        else:
            print(f"   âŒ ì‹¤íŒ¨")
    except Exception as e:
        print(f"   âŒ ì˜¤ë¥˜: {e}")
    
    # HTTPSë¡œ ë³€í™˜
    https_url = og_image_url.replace('http://', 'https://')
    print(f"\n   ë°©ë²• 2: HTTPS ë³€í™˜ URL")
    print(f"   URL: {https_url}")
    
    try:
        img_resp = session.get(https_url, headers=headers, timeout=10)
        print(f"   ìƒíƒœ: {img_resp.status_code}")
        print(f"   í¬ê¸°: {len(img_resp.content)} bytes")
        
        if img_resp.status_code == 200 and len(img_resp.content) > 1000:
            filepath = os.path.join(SAVE_DIR, 'test_https.jpg')
            with open(filepath, 'wb') as f:
                f.write(img_resp.content)
            print(f"   âœ… ì„±ê³µ! ì €ì¥: {filepath}")
        else:
            print(f"   âŒ ì‹¤íŒ¨")
    except Exception as e:
        print(f"   âŒ ì˜¤ë¥˜: {e}")
    
    print("\nğŸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")

if __name__ == '__main__':
    test_http_direct()
