"""
ë‚˜ì£¼ì‹œì²­ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì§„ë‹¨ ìŠ¤í¬ë¦½íŠ¸
- requests í—¤ë” ìµœì í™”ë¡œ 403 ìš°íšŒ ê°€ëŠ¥ ì—¬ë¶€ í…ŒìŠ¤íŠ¸
"""

import os
import requests
from bs4 import BeautifulSoup

BASE_URL = 'https://www.naju.go.kr'
LIST_URL = f'{BASE_URL}/www/administration/reporting/coverage'

def test_image_download():
    """ë¸Œë¼ìš°ì €ì™€ ìœ ì‚¬í•œ í—¤ë”ë¡œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹œë„"""
    
    # ë¸Œë¼ìš°ì €ì™€ ë™ì¼í•œ í—¤ë” êµ¬ì„±
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
        'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
        'Accept-Encoding': 'gzip, deflate, br',
        'Sec-Fetch-Dest': 'document',
        'Sec-Fetch-Mode': 'navigate',
        'Sec-Fetch-Site': 'none',
        'Sec-Fetch-User': '?1',
        'Upgrade-Insecure-Requests': '1',
        'Cache-Control': 'max-age=0',
    }
    
    session = requests.Session()
    session.headers.update(headers)
    
    print("ğŸ” Phase 1: ë‚˜ì£¼ì‹œì²­ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # 1ë‹¨ê³„: ëª©ë¡ í˜ì´ì§€ ì ‘ì† (ì¿ í‚¤ íšë“)
    print("\nğŸ“‹ 1ë‹¨ê³„: ëª©ë¡ í˜ì´ì§€ ì ‘ì†...")
    try:
        resp = session.get(LIST_URL, timeout=10)
        print(f"   ìƒíƒœ ì½”ë“œ: {resp.status_code}")
        print(f"   ì¿ í‚¤: {dict(session.cookies)}")
    except Exception as e:
        print(f"   âŒ ëª©ë¡ í˜ì´ì§€ ì ‘ì† ì‹¤íŒ¨: {e}")
        return False
    
    # 2ë‹¨ê³„: ì²« ë²ˆì§¸ ê¸°ì‚¬ ìƒì„¸ í˜ì´ì§€ ì ‘ì†
    print("\nğŸ“° 2ë‹¨ê³„: ì²« ë²ˆì§¸ ê¸°ì‚¬ ìƒì„¸ í˜ì´ì§€ ì ‘ì†...")
    soup = BeautifulSoup(resp.text, 'html.parser')
    first_link = soup.select_one('tbody tr a[href*="coverage?idx="]')
    
    if not first_link:
        print("   âŒ ê¸°ì‚¬ ë§í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    href = first_link.get('href', '')
    detail_url = f"{BASE_URL}{href.replace('&amp;', '&')}"
    print(f"   ìƒì„¸ URL: {detail_url}")
    
    # Referer ì„¤ì • í›„ ìƒì„¸ í˜ì´ì§€ ìš”ì²­
    session.headers.update({
        'Referer': LIST_URL,
        'Sec-Fetch-Site': 'same-origin',
    })
    
    try:
        detail_resp = session.get(detail_url, timeout=10)
        print(f"   ìƒíƒœ ì½”ë“œ: {detail_resp.status_code}")
    except Exception as e:
        print(f"   âŒ ìƒì„¸ í˜ì´ì§€ ì ‘ì† ì‹¤íŒ¨: {e}")
        return False
    
    # 3ë‹¨ê³„: og:image ì¶”ì¶œ
    print("\nğŸ–¼ï¸ 3ë‹¨ê³„: og:image ë©”íƒ€ íƒœê·¸ ì¶”ì¶œ...")
    detail_soup = BeautifulSoup(detail_resp.text, 'html.parser')
    og_image = detail_soup.find('meta', property='og:image')
    
    if not og_image or not og_image.get('content'):
        print("   âš ï¸ og:image íƒœê·¸ê°€ ì—†ìŠµë‹ˆë‹¤. (ì´ë¯¸ì§€ ì—†ëŠ” ê¸°ì‚¬)")
        return True  # ì´ë¯¸ì§€ê°€ ì—†ëŠ” ê²ƒì€ ì„±ê³µìœ¼ë¡œ ê°„ì£¼
    
    image_url = og_image['content']
    print(f"   ì´ë¯¸ì§€ URL: {image_url}")
    
    # 4ë‹¨ê³„: ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹œë„
    print("\nğŸ“¥ 4ë‹¨ê³„: ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹œë„...")
    
    # ì´ë¯¸ì§€ ìš”ì²­ìš© í—¤ë”
    session.headers.update({
        'Referer': detail_url,
        'Accept': 'image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8',
        'Sec-Fetch-Dest': 'image',
        'Sec-Fetch-Mode': 'no-cors',
    })
    
    try:
        img_resp = session.get(image_url, timeout=10)
        print(f"   ìƒíƒœ ì½”ë“œ: {img_resp.status_code}")
        print(f"   Content-Type: {img_resp.headers.get('Content-Type', 'N/A')}")
        print(f"   Content-Length: {len(img_resp.content)} bytes")
        
        if img_resp.status_code == 200 and len(img_resp.content) > 1000:
            # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì €ì¥
            save_dir = os.path.join(os.path.dirname(__file__), 'images', 'naju_test')
            os.makedirs(save_dir, exist_ok=True)
            filepath = os.path.join(save_dir, 'test_image.jpg')
            
            with open(filepath, 'wb') as f:
                f.write(img_resp.content)
            
            print(f"\nâœ… ì„±ê³µ! ì´ë¯¸ì§€ ì €ì¥ë¨: {filepath}")
            print(f"   íŒŒì¼ í¬ê¸°: {os.path.getsize(filepath)} bytes")
            return True
        else:
            print(f"\nâŒ ì‹¤íŒ¨: ìƒíƒœ ì½”ë“œ {img_resp.status_code} ë˜ëŠ” ë¹ˆ ì‘ë‹µ")
            return False
            
    except Exception as e:
        print(f"   âŒ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False


if __name__ == '__main__':
    success = test_image_download()
    
    print("\n" + "=" * 50)
    if success:
        print("ğŸ‰ ê²°ë¡ : requests ë°©ì‹ìœ¼ë¡œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥!")
        print("   â†’ naju_scraper.pyì— í—¤ë” ì„¤ì • ë°˜ì˜ ê¶Œì¥")
    else:
        print("âš ï¸ ê²°ë¡ : requests ë°©ì‹ ì‹¤íŒ¨, Playwright ë§ˆì´ê·¸ë ˆì´ì…˜ í•„ìš”")
